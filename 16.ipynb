{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b963f3",
   "metadata": {},
   "source": [
    "<h1>3 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e2f70",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 3**\n",
    "**«Решение систем линейных алгебраических уравнений методом Гаусса. Условие устойчивости вычислений. Варианты с частичным выбором ведущего элемента (по столбцу) и полным выбором по всей матрице.»**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Постановка задачи\n",
    "\n",
    "Имеется система из $n$ линейных уравнений с $n$ неизвестными:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "a_{11}x_1 + a_{12}x_2 + \\dots + a_{1n}x_n = b_1,\\\\\n",
    "a_{21}x_1 + a_{22}x_2 + \\dots + a_{2n}x_n = b_2,\\\\\n",
    "\\ \\ \\ \\vdots\\ \\ \\ \\quad\\quad\\vdots\\quad\\quad\\ddots\\quad\\vdots\\\\\n",
    "a_{n1}x_1 + a_{n2}x_2 + \\dots + a_{nn}x_n = b_n.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "В матричной форме это записывается как\n",
    "\n",
    "$$\n",
    "A\\,x = b,\\quad \n",
    "A = [a_{ij}]_{n\\times n},\\quad \n",
    "x=(x_1,\\dots,x_n)^T,\\quad\n",
    "b=(b_1,\\dots,b_n)^T.\n",
    "$$\n",
    "\n",
    "Прямое применение правила Крамера здесь неэффективно: вычисление $(n\\!+\\!1)$ детерминантов порядка $n$ требует $\\mathcal O((n+1)\\,n!\\,n)$ операций и быстро становится невыполнимым даже при умеренных $n$ .\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Суть метода Гаусса\n",
    "\n",
    "1. **Прямой ход (последовательное исключение).**\n",
    "\n",
    "   * Цель: превратить матрицу $A$ в верхнюю треугольную форму.\n",
    "   * На $k$-м шаге (для $k=1,\\dots,n-1$) мы “обнуляем” все элементы под диагональным $a_{kk}$: для каждого $i>k$\n",
    "\n",
    "     $$\n",
    "       \\text{множитель } c = \\frac{a_{ik}^{(\\,\\text{текущая}\\,)}}{a_{kk}^{(\\,\\text{текущая}\\,),}}\n",
    "       \\quad\n",
    "       \\text{замена уравнения }i:\\quad\n",
    "       a_{ij}\\;\\leftarrow\\;a_{ij}-c\\,a_{kj},\\quad\n",
    "       b_i\\;\\leftarrow\\;b_i-c\\,b_k,\n",
    "     $$\n",
    "\n",
    "     при $j=k,\\dots,n$.\n",
    "   * В результате получаем систему с треугольной матрицей коэффициентов:\n",
    "\n",
    "     $$\n",
    "     \\begin{pmatrix}\n",
    "       a_{11} & *      & \\dots & *\\\\\n",
    "       0      & a'_{22}& \\dots & *\\\\\n",
    "       \\vdots & \\vdots &\\ddots &\\vdots\\\\\n",
    "       0      & 0      & \\dots & a^{(n)}_{nn}\n",
    "     \\end{pmatrix}.\n",
    "     $$\n",
    "\n",
    "2. **Обратный ход (решение треугольной системы).**\n",
    "\n",
    "   * Снизу вверх находим\n",
    "\n",
    "     $$\n",
    "       x_n = \\frac{b_n}{a_{nn}},\\quad\n",
    "       x_k = \\frac{1}{a_{kk}}\\Bigl(b_k - \\sum_{i=k+1}^n a_{ki}\\,x_i\\Bigr),\\quad k=n-1,\\dots,1.\n",
    "     $$\n",
    "\n",
    "**Объём вычислений** при обычном методе Гаусса \\~$\\frac13n^3 + \\mathcal O(n^2)$ арифметических операций .\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Устойчивость вычислений и выбор ведущего элемента\n",
    "\n",
    "При стандартном алгоритме каждый шаг деления на $a_{kk}$ требует, чтобы этот элемент был отличен от нуля. Но даже если он ненулевой, он может быть очень мал по сравнению с другими коэффициентами, что приводит к **росту погрешностей**:\n",
    "\n",
    "$$\n",
    "\\Delta a_{ij}\\;\\mapsto\\;\\Delta a_{ij} - c\\,\\Delta a_{kj},\\quad c=\\frac{a_{ik}}{a_{kk}}.\n",
    "$$\n",
    "\n",
    "Если $|c|>1$, то погрешность “растет лавинообразно”.\n",
    "\n",
    "Чтобы этого избежать, перед исключением $x_k$ находят **главный (ведущий) элемент** — максимальный по модулю среди кандидатов на место $a_{kk}$ — и **меняют строки** так, чтобы он оказался на диагонали. Тогда\n",
    "\n",
    "$$\n",
    "|c| = \\Bigl|\\frac{a_{ik}}{a_{kk}}\\Bigr| \\le 1,\n",
    "$$\n",
    "\n",
    "и метод становится устойчивее.\n",
    "\n",
    "* **Частичный выбор**: ищем максимум в столбце $k$ (ниже или на диагонали), меняем только строки.\n",
    "* **Полный выбор**: ищем максимум в оставшейся (невырожденной) части матрицы $A_{k:n,k:n}$, меняем и строки, и столбцы. При перестановке столбцов меняется порядок переменных — его нужно запомнить и восстановить после решения.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Варианты метода\n",
    "\n",
    "1. **Без выбора ведущего элемента.**\n",
    "   Простая схема, но **неустойчива**, может “упасть” на делении на ноль или нарастании погрешностей.\n",
    "\n",
    "2. **С частичным выбором по столбцу.**\n",
    "   Надежный, находит главный элемент в каждом столбце, переставляет строки, **устойчивость** достаточно хорошая и **сложность** остаётся $\\sim\\frac13n^3$.\n",
    "\n",
    "3. **С полным выбором по матрице.**\n",
    "   Меняем и строки, и столбцы, чуть более устойчива, но дороже по сравнению: на каждом шаге ищем максимум среди $(n-k+1)^2$ элементов и ведём учёт порядка переменных.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Примеры\n",
    "\n",
    "### Пример 1. Простая система $3\\times3$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "3x + 4y + 5z = 9,\\\\\n",
    "x + 2y + 3z = 8,\\\\\n",
    "2x + 4y + 5z = 7.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1. **Матрица и вектор:**\n",
    "\n",
    "   $$\n",
    "   A = \\begin{pmatrix}\n",
    "   3 & 4 & 5\\\\\n",
    "   1 & 2 & 3\\\\\n",
    "   2 & 4 & 5\n",
    "   \\end{pmatrix},\\quad\n",
    "   b=\\begin{pmatrix}9\\\\8\\\\7\\end{pmatrix}.\n",
    "   $$\n",
    "2. **Шаг 1 (исключаем $x$ из уравнений 2 и 3):**\n",
    "\n",
    "   $$\n",
    "   c_{21}=\\frac{1}{3},\\quad c_{31}=\\frac{2}{3};\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "     \\text{Row}_2\\;\\leftarrow\\;\\text{Row}_2 - \\tfrac13\\,\\text{Row}_1\n",
    "     \\;\\Rightarrow\\;\\bigl(0,\\;2-\\tfrac{4}{3},\\;3-\\tfrac{5}{3}\\;\\bigr|\\;8-3\\bigr)\n",
    "     =(0,\\tfrac23,\\tfrac{4}{3}\\mid5);\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "     \\text{Row}_3\\;\\leftarrow\\;\\text{Row}_3 - \\tfrac23\\,\\text{Row}_1\n",
    "     \\;\\Rightarrow\\;(0,\\;4-\\tfrac{8}{3},\\;5-\\tfrac{10}{3}\\mid7-6)\n",
    "     =(0,\\tfrac{4}{3},\\tfrac{5}{3}\\mid1).\n",
    "   $$\n",
    "\n",
    "   Получили:\n",
    "\n",
    "   $$\n",
    "   \\begin{pmatrix}\n",
    "   3 & 4 & 5 &\\mid&9\\\\\n",
    "   0 & \\tfrac23 & \\tfrac43 &\\mid&5\\\\\n",
    "   0 & \\tfrac43 & \\tfrac53 &\\mid&1\n",
    "   \\end{pmatrix}.\n",
    "   $$\n",
    "3. **Шаг 2 (исключаем $y$ из 3-го уравнения):**\n",
    "   $c_{32}=(\\tfrac43)/(\\tfrac23)=2$.\n",
    "\n",
    "   $$\n",
    "     \\text{Row}_3\\;\\leftarrow\\;\\text{Row}_3 - 2\\,\\text{Row}_2\n",
    "     \\;\\Rightarrow\\;(0,0,\\;\\tfrac{5}{3}-2\\cdot\\tfrac{4}{3}\\mid1-2\\cdot5)\n",
    "     =(0,0,-1\\mid-9).\n",
    "   $$\n",
    "\n",
    "   Система становится\n",
    "\n",
    "   $$\n",
    "   \\begin{pmatrix}\n",
    "   3 & 4 & 5 &\\mid&9\\\\\n",
    "   0 & \\tfrac23 & \\tfrac43 &\\mid&5\\\\\n",
    "   0 & 0 & -1 &\\mid&-9\n",
    "   \\end{pmatrix}.\n",
    "   $$\n",
    "4. **Обратный ход:**\n",
    "\n",
    "   $$\n",
    "     z = x_3 = \\frac{-9}{-1} = 9;\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "     y = \\frac{5 - \\tfrac43\\cdot9}{\\tfrac23}\n",
    "       = \\frac{5 - 12}{\\tfrac23}\n",
    "       = \\frac{-7}{\\tfrac23}\n",
    "       = -\\frac{7}{1}\\cdot\\frac{3}{2}\n",
    "       = -\\tfrac{21}{2} = -10.5;\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "     x = \\frac{9 - 4\\cdot(-10.5) - 5\\cdot9}{3}\n",
    "       = \\frac{9 + 42 - 45}{3}\n",
    "       = \\frac{6}{3} = 2.\n",
    "   $$\n",
    "\n",
    "   **Ответ:** $(x,y,z) = (2,\\,-10.5,\\,9)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Пример 2. Система с нулевым первым элементом (демонстрация частичного выбора)\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "0x + 2y +  z = 5,\\\\\n",
    " x +  y +  z = 6,\\\\\n",
    "2x + 3y + 4z =11.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Здесь на первом шаге $a_{11}=0$, поэтому **частично** меняем первую строку на ту, где в первом столбце стоит ненулевое число (максимальное по модулю из строк 1–3):\n",
    "\n",
    "* Смотрим столбец 1: $\\{0,1,2\\}$ → выбираем $2$ (строка 3).\n",
    "* Меняем строки 1↔️3.\n",
    "\n",
    "Получаем эквивалентную систему\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "2x + 3y + 4z =11,\\\\\n",
    " x +  y +  z = 6,\\\\\n",
    "0x + 2y +  z = 5.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Дальше действуем, как в обычном методе:\n",
    "\n",
    "1. **Исключаем $x$** из строк 2 и 3:\n",
    "\n",
    "   $$\n",
    "     c_{21}=\\tfrac12,\\quad\n",
    "     \\text{Row}_2 \\leftarrow \\text{Row}_2 - \\tfrac12\\,\\text{Row}_1\n",
    "     \\;\\Rightarrow\\;(0,\\;1-\\tfrac{3}{2},\\;1-\\tfrac{4}{2}\\mid6-\\tfrac{11}{2})\n",
    "     =(0,-\\tfrac12,-1\\mid\\tfrac{1}{2});\n",
    "   $$\n",
    "\n",
    "   строку 3 менять не нужно (там $x$ уже отсутствует).\n",
    "2. **Исключаем $y$** из строки 3:\n",
    "\n",
    "   $$\n",
    "     c_{32}=\\frac{2}{-1/2}=-4,\\quad\n",
    "     \\text{Row}_3\\leftarrow\\text{Row}_3 -(-4)\\,\\text{Row}_2\n",
    "     =(0,0,\\;1-(-4)\\cdot(-1)\\mid5-(-4)\\cdot\\tfrac12)\n",
    "     =(0,0,-3\\mid7).\n",
    "   $$\n",
    "3. **Обратный ход:**\n",
    "\n",
    "   $$\n",
    "     z = \\frac{7}{-3} = -\\tfrac73,\\quad\n",
    "     y = \\frac{\\tfrac12 - (-1)\\cdot(-\\tfrac73)}{-\\tfrac12}\n",
    "       = \\frac{\\tfrac12 - \\tfrac73}{-\\tfrac12}\n",
    "       = \\frac{-\\tfrac{11}{6}}{-\\tfrac12}\n",
    "       = \\tfrac{11}{6}\\cdot2 = \\tfrac{11}{3},\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "     x = \\frac{11 - 3\\cdot\\tfrac{11}{3} - 4\\cdot(-\\tfrac73)}{2}\n",
    "       = \\frac{11 -11 + \\tfrac{28}{3}}{2}\n",
    "       = \\frac{\\tfrac{28}{3}}{2} = \\tfrac{14}{3}.\n",
    "   $$\n",
    "\n",
    "   **Ответ:** $\\bigl(x,y,z\\bigr)=\\bigl(\\tfrac{14}{3},\\,\\tfrac{11}{3},\\,-\\tfrac73\\bigr)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Комментарии к полному выбору\n",
    "\n",
    "Если же на каждом шаге искать **максимум не только в столбце**, но и во **всей** необработанной части матрицы, то придется переставлять **и столбцы**, и **строки**. После решения нужно будет “распутать” полученный порядок переменных. Алгоритм становится более затратным (по сравнению с выбором по столбцу), и на практике, как правило, достаточно **частичного** выбора ведущего элемента.\n",
    "\n",
    "---\n",
    "\n",
    "### Итоговая схема (частичный выбор)\n",
    "\n",
    "1. Для $k=1..n-1$:\n",
    "\n",
    "   * Найти в столбце $k$ (строки $k..n$) максимальный по модулю элемент.\n",
    "   * Поменять строки так, чтобы он оказался на $(k,k)$.\n",
    "   * Выполнить исключение $x_k$ из строк $k+1..n$.\n",
    "2. Обратным ходом найти $x_n,x_{n-1},\\dots,x_1$.\n",
    "\n",
    "Метод обеспечивает **устойчивую** и **эффективную** реализацию с $\\mathcal O(n^3)$ операций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae0b9e",
   "metadata": {},
   "source": [
    "<h1>3 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7859611",
   "metadata": {},
   "source": [
    "**Шпаргалка по билету № 3**\n",
    "**«Метод Гаусса. Устойчивость. Частичный и полный выбор ведущего элемента»**\n",
    "\n",
    "---\n",
    "\n",
    "1. **Суть метода**\n",
    "\n",
    "   * Прямой ход: приводим $A$ к верхнетреугольному виду, обнуляя ниже диагонали\n",
    "   * Обратный ход: решаем полученную треугольную систему снизу вверх\n",
    "\n",
    "2. **Алгоритм (частичный выбор)**\n",
    "\n",
    "   1. Для $k=1,\\dots,n-1$:\n",
    "\n",
    "      * в столбце $k$ (строки $k..n$) ищем элемент max |aᵢₖ|\n",
    "      * меняем строку $k$ и ту, где найден максимум\n",
    "      * для $i=k+1..n$:\n",
    "        $\\displaystyle c = \\frac{a_{i\\,k}}{a_{k\\,k}},\\quad\\text{Row}_i \\leftarrow \\text{Row}_i - c\\,\\text{Row}_k$\n",
    "   2. Для $k=n..1$:\n",
    "      $\\displaystyle x_k = \\frac{1}{a_{k\\,k}}\\Bigl(b_k - \\sum_{j=k+1}^n a_{k\\,j}x_j\\Bigr)$\n",
    "\n",
    "3. **Устойчивость**\n",
    "\n",
    "   * Без выбора ведущего: возможны деления на малые «псевдониули» → накопление погрешностей\n",
    "   * Частичный выбор (по столбцу): гарантирует $|c|\\le1$, достаточная устойчивость\n",
    "   * Полный выбор (по всей матрице): ещё более устойчивает, но сложнее (перестановка столбцов → учёт порядка переменных)\n",
    "\n",
    "4. **Сложность**\n",
    "   $\\displaystyle \\tfrac13n^3 + O(n^2)$ операций\n",
    "\n",
    "5. **Варианты**\n",
    "\n",
    "   * Без выбора: простая, но неустойчивая\n",
    "   * Частичный выбор: оптимальный баланс надёжности и скорости\n",
    "   * Полный выбор: максимальная устойчивость, больше затрат на поиск и перестановки\n",
    "\n",
    "---\n",
    "\n",
    "*Метод Гаусса с частичным выбором ведущего элемента – стандартная, эффективная и устойчивая схема решения СЛАУ.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e471a",
   "metadata": {},
   "source": [
    "<h1>4 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a479b4",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 4**\n",
    "**«Решение системы линейных алгебраических уравнений методом Гаусса. Приведение к треугольной форме с единичной диагональю и к диагональной форме (метод Гаусса–Жордана). Оценка количества арифметических операций, затрачиваемых на прямой и обратный ход. Матричная формулировка метода Гаусса, его связь с LU-факторизацией матрицы коэффициентов. Вычисление обратной матрицы $A^{-1}$».**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Приведение к треугольной форме с единичной диагональю\n",
    "\n",
    "1. **Идея «деления ведущего уравнения**\n",
    "   На $k$-м шаге после выбора (и, при необходимости, перестановки) ведущего элемента $a_{kk}$ делим $k$-е уравнение на $a_{kk}$, чтобы получить $a'_{kk}=1$. Тогда\n",
    "\n",
    "   $$\n",
    "     a'_{k,i} = \\frac{a_{k,i}}{a_{kk}},\\quad \n",
    "     b'_k = \\frac{b_k}{a_{kk}},\\quad i=k+1,\\dots,n.\n",
    "   $$\n",
    "\n",
    "2. **Исключение**\n",
    "   Для каждого $i>k$ прибавляем к $i$-му уравнению «новое» $k$-е, умноженное на $-a_{i,k}$.\n",
    "   В результате в получившейся верхнетреугольной матрице на диагонали окажутся единицы, а поддиагональные элементы обнулятся .\n",
    "\n",
    "3. **Обратный ход**\n",
    "   Поскольку на диагонали — единицы, обратный ход сводится к\n",
    "\n",
    "   $$\n",
    "     x_n = \\tilde b_n,\\quad\n",
    "     x_k = \\tilde b_k - \\sum_{i=k+1}^n \\tilde a_{k,i}\\,x_i,\\quad k=n-1,\\dots,1.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Метод Гаусса–Жордана (полное приведение к диагональной форме)\n",
    "\n",
    "* **Прямой ход**\n",
    "  Каждое неизвестное «исключается» не только из уравнений ниже, но и выше: после обработки $k$-го столбца все элементы вне диагонали становятся нулями.\n",
    "* **Обратный ход**\n",
    "  В чистом варианте отсутствует — после прямого хода система сразу имеет вид\n",
    "  $\\mathrm{diag}(d_1,\\dots,d_n)\\,x = \\tilde b$,\n",
    "  и остаётся лишь разделить каждое уравнение на $d_k$.\n",
    "* **Сравнение объёмов**\n",
    "  Прямой ход Гаусса–Жордана требует\n",
    "\n",
    "  $$\n",
    "    (n-1)^2\\text{ делений,}\\quad\n",
    "    \\tfrac{n(n^2-3)+2}2\\text{ умножений и столько же сложений},\n",
    "  $$\n",
    "\n",
    "  то есть порядка $n^3$ при отсутствии обратного хода. Обычный метод Гаусса тратит на прямой ход $\\sim n^3/3$ операций, а обратный — $\\sim n^2/2$ операций . При $n=100$ общее число операций соответственно $1{,}01\\cdot10^6$ и $0{,}682\\cdot10^6$, поэтому метод Жордана применяется редко.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Оценка числа арифметических операций\n",
    "\n",
    "1. **Прямой ход (Гаусс)**\n",
    "   На $k$-м шаге выполняется\n",
    "\n",
    "   $$\n",
    "     n-k\\text{ делений},\\quad\n",
    "     (n-k)(n-k+1)\\text{ умножений и сложений}.\n",
    "   $$\n",
    "\n",
    "   Всего:\n",
    "\n",
    "   $$\n",
    "     \\frac{n(n-1)}2\\text{ делений},\\quad\n",
    "     \\frac{n(n^2-1)}3\\text{ умножений и }+\\text{сложений}.\n",
    "   $$\n",
    "\n",
    "2. **Обратный ход**\n",
    "\n",
    "   $$\n",
    "     n\\text{ делений},\\quad\n",
    "     \\frac{n(n-1)}2\\text{ умножений и вычитаний}.\n",
    "   $$\n",
    "\n",
    "3. **Итог**\n",
    "\n",
    "   $$\n",
    "     \\mathcal O(n^3)\\text{ операций (ведущая константа }\\tfrac13).\n",
    "   $$\n",
    "\n",
    "   Обратный ход даёт лишь $\\mathcal O(n^2)$ операций и с ростом $n$ становится незначительным .\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Матричная формулировка и связь с LU-факторизацией\n",
    "\n",
    "1. **Матрицы преобразований**\n",
    "   Каждый шаг прямого хода — умножение слева на нижнетреугольную «элиминаторную» матрицу $M_k$. После $n-1$ шагов\n",
    "\n",
    "   $$\n",
    "     U = M_{n-1}\\cdots M_1\\,A,\n",
    "   $$\n",
    "\n",
    "   где $U$ — верхнетреугольная матрица. Значит\n",
    "\n",
    "   $$\n",
    "     A = (M_{n-1}\\cdots M_1)^{-1}\\,U = L\\,U,\n",
    "   $$\n",
    "\n",
    "   где $L = M_1^{-1}M_2^{-1}\\cdots M_{n-1}^{-1}$ — нижнетреугольная матрица с единичной диагональю. Это и есть **LU-разложение** матрицы $A$ .\n",
    "\n",
    "2. **Решение через LU**\n",
    "   Запишем $LU\\,x=b$. Вводим вспомогательный вектор $z=U\\,x$. Тогда\n",
    "\n",
    "   $$\n",
    "     L\\,z = b,\\quad U\\,x = z,\n",
    "   $$\n",
    "\n",
    "   что даёт две треугольные системы, решаемые быстрыми «вперёд» и «назад» алгоритмами.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Вычисление обратной матрицы $A^{-1}$\n",
    "\n",
    "1. По определению\n",
    "   $\\displaystyle A\\,A^{-1}=E$.\n",
    "2. Обратную можно найти, решив $n$ систем\n",
    "\n",
    "   $$\n",
    "     A\\,z_k = e_k,\\quad k=1,\\dots,n,\n",
    "   $$\n",
    "\n",
    "   где $e_k$ — $k$-й базисный вектор. Столбцы $z_k$ образуют $A^{-1}$.\n",
    "3. При наличии LU-разложения вместо каждого прямого хода решают две треугольные системы; благодаря единожды выполненному факторизированию это эффективно .\n",
    "\n",
    "---\n",
    "\n",
    "## Примеры\n",
    "\n",
    "### Пример 1. 2×2, треугольная форма с единичной диагональю\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "4 & 3\\\\\n",
    "2 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}x\\\\y\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}11\\\\5\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "1. Делим 1-е уравнение на 4:\n",
    "   $\\;x + \\tfrac34y = \\tfrac{11}4$.\n",
    "2. Исключаем $x$ из 2-го:\n",
    "   $\\;(2x+y) -2(x+\\tfrac34y) = 5 -2\\cdot\\tfrac{11}4\\ \\Longrightarrow\\ -\\tfrac12y=-\\tfrac{3}2$;\n",
    "   $y=3$.\n",
    "3. $x = \\tfrac{11}4 - \\tfrac34\\cdot3 = -\\tfrac1{4}$.\n",
    "\n",
    "### Пример 2. 3×3, Gauss–Jordan, вычисление $A^{-1}$\n",
    "\n",
    "$$\n",
    "A=\\begin{pmatrix}\n",
    "2&1&0\\\\\n",
    "1&2&1\\\\\n",
    "0&1&2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Составляем расширенную матрицу $[A\\mid E]$ и приводим её методом Жордана к $[E\\mid A^{-1}]$. В итоге получаем\n",
    "\n",
    "$$\n",
    "A^{-1}=\\frac1{4}\n",
    "\\begin{pmatrix}\n",
    "3&-2&1\\\\\n",
    "-2&4&-2\\\\\n",
    "1&-2&3\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "(Детали алгебры — деления строк на ведущие элементы и обнуления остальных — опускаем в силу ограничений шпаргалки.)\n",
    "\n",
    "---\n",
    "\n",
    "**Итог:**\n",
    "\n",
    "* Метод Гаусса с единичной диагональю избавляет от операций деления в обратном ходе.\n",
    "* Гаусс–Жордан сразу даёт диагональную систему, но дороже по операциям.\n",
    "* LU-разложение связывает обе задачи: решение СЛАУ и обращение матриц через треугольные множители.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562616fb",
   "metadata": {},
   "source": [
    "<h1>4 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d6a68",
   "metadata": {},
   "source": [
    "**Шпаргалка по билету № 4**\n",
    "**«Метод Гаусса, Гаусса–Жордана, LU-факторизация, обратная матрица»**\n",
    "\n",
    "---\n",
    "\n",
    "1. **Прямой ход Гаусса (единичная диагональ)**\n",
    "\n",
    "   * На шаге k:\n",
    "\n",
    "     1. При необходимости выбрать ведущий элемент (частичный/полный выбор) и переставить строки/столбцы.\n",
    "     2. Разделить k-е уравнение на $a_{kk}$ → на диагонали единица.\n",
    "     3. Для $i=k+1..n$: вычесть $a_{ik}\\times$(новое k-е уравнение) → обнулить элементы под диагональю.\n",
    "\n",
    "2. **Обратный ход**\n",
    "\n",
    "   $$\n",
    "   x_n = \\tilde b_n,\\quad\n",
    "   x_k = \\tilde b_k - \\sum_{j=k+1}^n \\tilde a_{kj}\\,x_j.\n",
    "   $$\n",
    "\n",
    "3. **Метод Гаусса–Жордана**\n",
    "\n",
    "   * Расширенный прямой ход: для каждого k обнуляем все вне диагонали (и выше, и ниже).\n",
    "   * После прямого хода сразу диагональная матрица → делим на диагональные элементы.\n",
    "   * Объём ≈ $n^3$ операций (без отдельного обратного хода).\n",
    "\n",
    "4. **Оценка затрат**\n",
    "\n",
    "   * Гаусс-прямой: $\\sim\\frac13n^3$ оп.; обратный: $\\sim\\frac12n^2$ оп.\n",
    "   * Жордан-прямой: $\\sim n^3$ оп.\n",
    "\n",
    "5. **LU-факторизация**\n",
    "\n",
    "   $$\n",
    "     A = L\\,U,\\quad\n",
    "     L\\text{—нижнетреугольная (единицы на диаг.)},\\ \n",
    "     U\\text{—верхнетреугольная}.\n",
    "   $$\n",
    "\n",
    "   Решение через две треугольные системы $Lz=b,\\;Ux=z$.\n",
    "\n",
    "6. **Обращение матрицы**\n",
    "\n",
    "   * Решаем $A\\,X=I$ по столбцам: $A z_k = e_k$.\n",
    "   * При наличии LU → два треугольных решения для каждого $e_k$.\n",
    "   * Результат — $A^{-1}=[z_1,\\dots,z_n]$.\n",
    "\n",
    "---\n",
    "\n",
    "*Всё в рамках $\\mathcal O(n^3)$ вычислений; стандартный подход — Гаусс с единичной диагональю + LU для многократных решений и обращения.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab51fac",
   "metadata": {},
   "source": [
    "<h1>5 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baec1cd",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 5**\n",
    "\n",
    "---\n",
    "\n",
    "### Тема\n",
    "\n",
    "**Решение нелинейного уравнения методом деления отрезка (бисекции). Условия применимости метода и скорость сходимости к решению.**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Введение в метод\n",
    "\n",
    "1. **Задача.** Найти корень уравнения\n",
    "\n",
    "   $$\n",
    "   F(x) = 0\n",
    "   $$\n",
    "\n",
    "   в заранее заданном отрезке $[a,b]$.\n",
    "\n",
    "2. **Основная идея.** Если на концах отрезка функция принимает значения разных знаков,\n",
    "\n",
    "   $$\n",
    "   F(a)\\cdot F(b)<0,\n",
    "   $$\n",
    "\n",
    "   то по теореме Больцано–Коши на отрезке существует хотя бы один корень. Метод бисекции последовательно «разрезает» этот отрезок пополам, локализуя корень всё точнее.\n",
    "\n",
    "3. **Классификация.** Это итерационный метод: начиная с отрезка $[a,b]$, на каждой итерации мы получаем новый, вдвое более короткий отрезок, содержащий корень.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Условия применимости\n",
    "\n",
    "1. **Непрерывность.** $F$ должна быть непрерывна на $[a,b]$.\n",
    "2. **Противоположные знаки на концах.** $F(a)\\cdot F(b)<0$.\n",
    "3. **Один корень на отрезке.** Желательно, чтобы функция меняла знак только один раз («простая» изоляция корня).\n",
    "4. **Запас прочности по вычислительной арифметике.**\n",
    "\n",
    "   * При реализации на компьютере лучше проверять знак произведения через «знаковую функцию»\n",
    "\n",
    "     $$\n",
    "       \\operatorname{sign}(y)=\\frac{y}{|y|},\n",
    "     $$\n",
    "\n",
    "     чтобы избежать проблем, когда из-за переполнения или «машинного нуля» $F(a)$ или $F(b)$ становятся буквально равны нулю в машинном представлении.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Алгоритм метода деления отрезка\n",
    "\n",
    "1. **Начало.** Заданы $a$, $b$ с $F(a)\\cdot F(b)<0$, а также критерии точности:\n",
    "\n",
    "   * по аргументу: длина отрезка $b-a\\le\\varepsilon$;\n",
    "   * (или) по значению функции: $|F(c)|\\le\\delta$.\n",
    "\n",
    "2. **Шаг итерации.**\n",
    "\n",
    "   1. Вычислить середину\n",
    "\n",
    "      $$\n",
    "        c = a + \\frac{b-a}{2}.\n",
    "      $$\n",
    "\n",
    "      Такой способ надёжнее, чем $(a+b)/2$, — он не «вываливается» за $[a,b]$ из-за округлений.\n",
    "   2. Посчитать $F(c)$.\n",
    "   3. Если выполнено хотя бы одно условие останова\n",
    "\n",
    "      $$\n",
    "        |F(c)| \\le \\delta\n",
    "        \\quad\\text{или}\\quad\n",
    "        \\frac{b-a}2 \\le \\varepsilon,\n",
    "      $$\n",
    "\n",
    "      то принять $c$ за приближённый корень и выйти.\n",
    "   4. Иначе сравнить знаки $F(a)$ и $F(c)$:\n",
    "\n",
    "      * если $F(a)\\cdot F(c)<0$, то корень в $[a,c]$ → положить $b=c$;\n",
    "      * иначе корень в $[c,b]$ → положить $a=c$.\n",
    "   5. Перейти к следующей итерации.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Скорость сходимости\n",
    "\n",
    "* После $n$ итераций длина текущего отрезка не превосходит\n",
    "\n",
    "  $$\n",
    "    L_n = \\frac{b-a}{2^n}.\n",
    "  $$\n",
    "* Следовательно, погрешность по аргументу (максимальное расстояние до истинного корня)\n",
    "\n",
    "  $$\n",
    "    \\delta_n \\le \\tfrac12 L_n = \\frac{b-a}{2^{n+1}}.\n",
    "  $$\n",
    "* Чтобы сократить начальную ошибку в $T$ раз, нужно примерно\n",
    "\n",
    "  $$\n",
    "    n \\approx \\log_2 T\n",
    "  $$\n",
    "\n",
    "  итераций.\n",
    "* Это **линейная** сходимость (ошибка убывает как геометрическая прогрессия с коэффициентом $1/2$).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Простой язык без «воды»\n",
    "\n",
    "> Представьте, что вы ищете точку, где кривая $y=F(x)$ пересекает ось $OX$.\n",
    "> Если на концах отрезка график «над» осью, а «под» осью — корень между ними.\n",
    "> Каждый раз берём середину, смотрим, в какой половине знак меняется,\n",
    "> и продолжаем поиск там. Шаг за шагом отрезок становится всё короче,\n",
    "> и вы «стягиваете» корень всё плотнее.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Примеры\n",
    "\n",
    "### Пример 1.\n",
    "\n",
    "**Уравнение:** $x^3 - x - 2 = 0$.\n",
    "**Изоляция корня:** на отрезке $[1,2]$\n",
    "\n",
    "* $F(1)=1-1-2=-2$;\n",
    "* $F(2)=8-2-2=4$;\n",
    "* знак меняется → есть корень.\n",
    "\n",
    "| Итерация | $[a,b]$           | $c$    | $F(c)$    | Новый отрезок     |\n",
    "| :------: | :---------------- | :----- | :-------- | :---------------- |\n",
    "|     1    | $1.000, 2.000]   | 1.500  | –0.125    | $1.500, 2.000]   |\n",
    "|     2    | $1.500, 2.000]   | 1.750  | 1.609375  | $1.500, 1.750]   |\n",
    "|     3    | $1.500, 1.750]   | 1.625  | –0.984375 | $1.625, 1.750]   |\n",
    "|     …    | …                 | …      | …         | …                 |\n",
    "|     5    | $1.6719, 1.6875] | 1.6797 | 0.0435    | $1.6719, 1.6797] |\n",
    "|     6    | $1.6719, 1.6797] | 1.6758 | –0.0208   | $1.6758, 1.6797] |\n",
    "\n",
    "Через 6 шагов длина отрезка ≈ 0.0039, корень ≈ 1.6784.\n",
    "\n",
    "---\n",
    "\n",
    "### Пример 2.\n",
    "\n",
    "**Уравнение:** $\\cos x - x = 0$.\n",
    "**Изоляция корня:** на $[0,\\,1]$\n",
    "\n",
    "* $F(0)=1$; $F(1)=\\cos1-1\\approx -0.46$.\n",
    "\n",
    "| Итерация | $[a,b]$          | $c$    | $F(c)$  | Новый отрезок     |\n",
    "| :------: | :--------------- | :----- | :------ | :---------------- |\n",
    "|     1    | $0.000, 1.000]  | 0.500  | 0.3776  | $0.500, 1.000]   |\n",
    "|     2    | $0.500, 1.000]  | 0.750  | –0.0183 | $0.500, 0.750]   |\n",
    "|     3    | $0.500, 0.750]  | 0.625  | 0.1790  | $0.625, 0.750]   |\n",
    "|     4    | $0.625, 0.750]  | 0.6875 | 0.0839  | $0.6875, 0.750]  |\n",
    "|     5    | $0.6875, 0.750] | 0.7188 | 0.0332  | $0.7188, 0.750]  |\n",
    "|     6    | $0.7188, 0.750] | 0.7344 | 0.0070  | $0.7344, 0.750]  |\n",
    "|     7    | $0.7344, 0.750] | 0.7422 | –0.0057 | $0.7344, 0.7422] |\n",
    "\n",
    "После 7 шагов корень локализован в отрезке длиной ≈ 0.0078, значение $x\\approx0.739$.\n",
    "\n",
    "---\n",
    "\n",
    "### Итог\n",
    "\n",
    "* **Надёжность.** Гарантированное сокращение погрешности вдвое при каждой итерации.\n",
    "* **Простота.** Не требует знания производных и сложных преобразований.\n",
    "* **Медленность.** Линейная сходимость: чтобы добавить одну точку «двойной» точности (уменьшить ошибку в 10 раз), нужно ∼ 3.3 итерации.\n",
    "\n",
    "Метод бисекции идеален для быстрого «грубо́го» нахождения корня и служит хорошей отправной точкой прежде чем переходить к более быстрым (но требовательным к гладкости) методам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b69592",
   "metadata": {},
   "source": [
    "<h1>5 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87411dd",
   "metadata": {},
   "source": [
    "**Билет № 5. Метод бисекции (деления отрезка)**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Постановка задачи\n",
    "\n",
    "Найти приближённый корень $x^*$ уравнения\n",
    "\n",
    "$$\n",
    "F(x) = 0\n",
    "$$\n",
    "\n",
    "на отрезке $[a,b]$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Условия применимости\n",
    "\n",
    "1. **Непрерывность**: $F$ непрерывна на $[a,b]$.\n",
    "2. **Изоляция корня**: $F(a)\\cdot F(b)<0$ (функция меняет знак ровно один раз).\n",
    "3. **Один корень**: желательно, чтобы внутри $[a,b]$ было только одно пересечение с осью $OX$.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Алгоритм метода\n",
    "\n",
    "1. **Инициализация**:\n",
    "\n",
    "   * Заданы $a$, $b$, критерии точности по аргументу $\\varepsilon$ и/или по функции $\\delta$.\n",
    "2. **Основной шаг** (итерация):\n",
    "\n",
    "   1. Вычислить середину\n",
    "\n",
    "      $$\n",
    "        c = a + \\frac{b-a}{2}.\n",
    "      $$\n",
    "   2. Оценить $F(c)$.\n",
    "   3. **Проверка завершения**:\n",
    "\n",
    "      * Если $\\lvert F(c)\\rvert \\le \\delta$ **или** $\\frac{b-a}{2} \\le \\varepsilon$, то принять $c$ за ответ и выйти.\n",
    "   4. **Локализация**:\n",
    "\n",
    "      * Если $F(a)\\,F(c)<0$, корень в $[a,c]$ → $b := c$.\n",
    "      * Иначе корень в $[c,b]$ → $a := c$.\n",
    "3. **Повторять**, пока не выполнится одно из условий остановки.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Скорость сходимости\n",
    "\n",
    "* **Линейная**: каждый шаг уменьшает длину отрезка вдвое.\n",
    "* После $n$ итераций длина отрезка\n",
    "\n",
    "  $$\n",
    "    \\frac{b-a}{2^n},\n",
    "  $$\n",
    "\n",
    "  а погрешность по корню\n",
    "\n",
    "  $$\n",
    "    \\le \\frac{b-a}{2^{n+1}}.\n",
    "  $$\n",
    "* Для снижения ошибки в $T$ раз нужно примерно $\\log_2 T$ шагов.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Достоинства и недостатки\n",
    "\n",
    "* **Плюсы**:\n",
    "\n",
    "  * Гарантированная сходимость при выполнении условий.\n",
    "  * Простота реализации (не требуются производные).\n",
    "* **Минусы**:\n",
    "\n",
    "  * Низкая скорость (много итераций для высокой точности).\n",
    "  * Не годится, если корень кратный или функция не меняет знак.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Краткая формулировка «для шпаргалки»\n",
    "\n",
    "> **Метод бисекции**:\n",
    ">\n",
    "> 1. Убеждаемся в наличии корня на $[a,b]$ по знакам $F(a)$ и $F(b)$.\n",
    "> 2. Берём середину $c$.\n",
    "> 3. Выбираем ту половину, где $F$ меняет знак, — там и ищем дальше.\n",
    "> 4. Повторяем, пока отрезок не станет достаточно малым.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759d170",
   "metadata": {},
   "source": [
    "<h1>6 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ccc75",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 6**\n",
    "\n",
    "---\n",
    "\n",
    "### Тема\n",
    "\n",
    "**Решение нелинейных уравнений методом простой итерации.**\n",
    "– Условия сходимости: сжимающие отображения и неподвижная точка.\n",
    "– Варианты выбора итерационной функции.\n",
    "– Решение систем уравнений.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Идея метода простой итерации\n",
    "\n",
    "1. **Исходная задача.** У нас есть уравнение\n",
    "\n",
    "   $$\n",
    "     F(x) = 0.\n",
    "   $$\n",
    "2. **Переход к форме итерации.** Переписываем его в эквивалентном виде\n",
    "\n",
    "   $$\n",
    "     x = \\varphi(x),\n",
    "   $$\n",
    "\n",
    "   так что все решения исходного и нового уравнения совпадают.\n",
    "3. **Алгоритм.**\n",
    "\n",
    "   1. Берём начальное приближение $x_0$.\n",
    "   2. Вычисляем\n",
    "\n",
    "      $$\n",
    "        x_{n+1} = \\varphi(x_n),\\quad n=0,1,2,\\dots\n",
    "      $$\n",
    "   3. Останавливаемся, когда $\\bigl|x_{n+1}-x_n\\bigr|\\le\\varepsilon$.\n",
    "4. Точка $x^*$, удовлетворяющая $x^*=\\varphi(x^*)$, называется **неподвижной** – это и есть наш корень.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Условия сходимости: сжимающие отображения\n",
    "\n",
    "Чтобы последовательность $\\{x_n\\}$ сходилась к $x^*$, достаточно, чтобы $\\varphi$ задавало **сжимающее отображение** на некотором отрезке $[a,b]$:\n",
    "\n",
    "$$\n",
    "\\bigl|\\varphi(x)-\\varphi(y)\\bigr|\\le q\\,|x-y|,\\quad q<1,\\;\\forall x,y\\in[a,b].\n",
    "$$\n",
    "\n",
    "По теореме о фиксированной точке:\n",
    "\n",
    "* Тогда единственная неподвижная точка $x^*\\in[a,b]$ существует и\n",
    "* Для любого $x_0\\in[a,b]$ итерации сходятся к $x^*$.\n",
    "\n",
    "**Практический критерий (через производную).**\n",
    "Если $\\varphi$ непрерывно дифференцируема на $[a,b]$ и\n",
    "\n",
    "$$\n",
    "\\max_{x\\in[a,b]}|\\varphi'(x)| = q < 1,\n",
    "$$\n",
    "\n",
    "то $\\varphi$ — сжимающее отображение, и метод сходится линейно.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Как выбрать итерационную функцию\n",
    "\n",
    "Из уравнения $F(x)=0$ можно получить семейство эквивалентных форм:\n",
    "\n",
    "$$\n",
    "x = x + g(x)\\,F(x),\n",
    "$$\n",
    "\n",
    "где $g(x)$ — произвольная функция, не обращающаяся в нуль на отрезке поиска. Тогда\n",
    "\n",
    "$$\n",
    "\\varphi(x) = x + g(x)\\,F(x).\n",
    "$$\n",
    "\n",
    "* **Метод релаксации**: $g(x)\\equiv C$ (константа).\n",
    "  Тогда\n",
    "  $\\varphi'(x)=1+C\\,F'(x)$, и условие сходимости\n",
    "  $-2< C\\,F'(x^*)<0$.\n",
    "* **Ньютоновская трактовка**: при $g(x)=-1/F'(x)$ получаем метод Ньютона (квадратичная сходимость), но это уже отдельная тема.\n",
    "\n",
    "Цель — подобрать $g(x)$ так, чтобы $|\\varphi'(x)|$ было как можно меньше на отрезке.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Решение систем уравнений\n",
    "\n",
    "Для системы\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "F_1(x,y,\\dots)=0,\\\\\n",
    "F_2(x,y,\\dots)=0,\\\\\n",
    "\\quad\\vdots\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "строят эквивалентную систему неподвижных точек\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x = \\varphi_1(x,y,\\dots),\\\\\n",
    "y = \\varphi_2(x,y,\\dots),\\\\\n",
    "\\qquad\\vdots\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "и итерационно вычисляют вектор\n",
    "$\\mathbf{x}_{n+1} = \\boldsymbol\\varphi(\\mathbf{x}_n)$.\n",
    "Сходимость обеспечивается тем же «сжатием», но уже в $n$-мерном пространстве (норма Якобиана $\\|\\partial\\varphi_i/\\partial x_j\\|<1$) .\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Простое объяснение\n",
    "\n",
    "> **Метод простой итерации** — это когда вы угадываете $x$, подставляете в «правую часть» вида $x=\\varphi(x)$, получаете новое «угадывание» и повторяете.\n",
    "> Чтобы эти угадывания «стягивались» к одному значению (корню), нужно, чтобы операция $x\\mapsto\\varphi(x)$ слегка «сжимала» все числа к настоящему корню (т. е. не растягивала их).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Примеры\n",
    "\n",
    "### Пример 1.\n",
    "\n",
    "**Уравнение:** $x^2-2=0$.\n",
    "**Цель:** найти $\\sqrt2\\approx1.4142$.\n",
    "**Итерация (метод средних):**\n",
    "\n",
    "$$\n",
    "\\varphi(x)=\\tfrac12\\Bigl(x+\\tfrac{2}{x}\\Bigr),\n",
    "$$\n",
    "\n",
    "тогда\n",
    "\n",
    "$$\n",
    "x_{n+1}=\\tfrac12\\Bigl(x_n+\\tfrac{2}{x_n}\\Bigr).\n",
    "$$\n",
    "\n",
    "Здесь $\\varphi'(x)=\\tfrac12\\Bigl(1 - \\tfrac{2}{x^2}\\Bigr)$,\n",
    "и около $x^*$ оно мало по модулю, что даёт быструю (квадратично близкую) сходимость .\n",
    "\n",
    "| $n$ | $x_n$  |\n",
    "| :-: | :----- |\n",
    "|  0  | 1.0    |\n",
    "|  1  | 1.5    |\n",
    "|  2  | 1.4167 |\n",
    "|  3  | 1.4142 |\n",
    "\n",
    "---\n",
    "\n",
    "### Пример 2.\n",
    "\n",
    "**Уравнение:** $\\cos x - x = 0$.\n",
    "**Итерация:**\n",
    "\n",
    "$$\n",
    "\\varphi(x)=\\cos x.\n",
    "$$\n",
    "\n",
    "Так как $|\\varphi'(x)|=|\\sin x|\\le1$, но на подходящем отрезке, например $[0,1]$, $\\max|\\sin x|\\approx0.84<1$, метод сходится линейно.\n",
    "\n",
    "| $n$ | $x_n$  |\n",
    "| :-: | :----- |\n",
    "|  0  | 0.5    |\n",
    "|  1  | 0.8776 |\n",
    "|  2  | 0.6390 |\n",
    "|  3  | 0.8027 |\n",
    "|  …  | …      |\n",
    "|  7  | 0.7391 |\n",
    "\n",
    "---\n",
    "\n",
    "### Пример 3. (Система из двух уравнений)\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "2x - y = 3,\\\\\n",
    "3y - x^2 = 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Перепишем в виде неподвижной точки:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x = \\tfrac{3+y}{2},\\\\\n",
    "y = \\tfrac{1 + x^2}{3}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Итерации:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x_{n+1} = \\tfrac{3 + y_n}{2},\\\\\n",
    "y_{n+1} = \\tfrac{1 + x_n^2}{3}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "При начальном $(x_0,y_0)=(1,1)$ получаем быстрое (линейное) стягивание к единственному решению.\n",
    "\n",
    "---\n",
    "\n",
    "**Вывод:**\n",
    "Метод простой итерации универсален и прозрачен, но его надёжность и скорость зависят от выбора $\\varphi(x)$ — именно этому посвящены критерии сжимающих отображений и анализ производной итерационной функции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03201b22",
   "metadata": {},
   "source": [
    "<h1>6 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f318bf",
   "metadata": {},
   "source": [
    "**Билет № 6. Метод простой итерации: шпаргалка**\n",
    "\n",
    "---\n",
    "\n",
    "1. **Переписывание уравнения**\n",
    "\n",
    "   $$\n",
    "   F(x)=0\\quad\\Longrightarrow\\quad x=\\varphi(x)\\quad(\\text{эквивалентно}).\n",
    "   $$\n",
    "\n",
    "2. **Итерационный процесс**\n",
    "\n",
    "   $$\n",
    "   x_{n+1}=\\varphi(x_n),\\quad n=0,1,2,\\dots\n",
    "   $$\n",
    "\n",
    "   Стоп-критерий: $|x_{n+1}-x_n|\\le\\varepsilon$.\n",
    "\n",
    "3. **Неподвижная точка**\n",
    "   Корень $x^*$ — это такая точка, что\n",
    "   $\\;x^*=\\varphi(x^*)$.\n",
    "\n",
    "4. **Условие сходимости (сжимающее отображение)**\n",
    "   На отрезке $[a,b]$:\n",
    "\n",
    "   $$\n",
    "   |\\varphi(x)-\\varphi(y)|\\le q\\;|x-y|,\\quad q<1.\n",
    "   $$\n",
    "\n",
    "   Достаточно: $\\max_{[a,b]}|\\varphi'(x)|=q<1$.\n",
    "\n",
    "5. **Выбор $\\varphi(x)$**\n",
    "\n",
    "   * **Релаксация**: $\\varphi(x)=x+C\\,F(x)$,\n",
    "     условие: $-2< C\\,F'(x^*)<0$.\n",
    "   * **Квадратное ускорение**: $\\varphi(x)=x-\\tfrac{F(x)}{F'(x)}$ (метод Ньютона).\n",
    "   * **Другие**: любой $g(x)\\neq0$ в $\\varphi(x)=x+g(x)\\,F(x)$, чтобы $|\\varphi'|$ был мал.\n",
    "\n",
    "6. **Системы уравнений**\n",
    "   Для $\\mathbf{F}(\\mathbf{x})=\\mathbf{0}$ строим\n",
    "   $\\;\\mathbf{x}=\\boldsymbol\\varphi(\\mathbf{x})$,\n",
    "   итерации $\\mathbf{x}_{n+1}=\\boldsymbol\\varphi(\\mathbf{x}_n)$.\n",
    "   Критерий: норма Якобиана $\\|\\partial\\varphi_i/\\partial x_j\\|<1$.\n",
    "\n",
    "---\n",
    "\n",
    "> **Ключ**: каждую итерацию «подставляй» в $\\varphi$ и проверяй, что функция «стягивает» значения (малый $|\\varphi'|$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68fcb6",
   "metadata": {},
   "source": [
    "<h1>7 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a743631",
   "metadata": {},
   "source": [
    "Вот развёрнутый ответ по пунктам “билета” и два примера, иллюстрирующих метод Ньютона.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Метод Ньютона для одного уравнения\n",
    "\n",
    "Пусть нужно найти корень уравнения\n",
    "\n",
    "$$\n",
    "F(x) = 0.\n",
    "$$\n",
    "\n",
    "1. **Идея.**\n",
    "   В окрестности приближения $x_n$ функция $F(x)$ заменяется её касательной:\n",
    "\n",
    "   $$\n",
    "   F(x)\\approx F(x_n) + F'(x_n)(x - x_n).\n",
    "   $$\n",
    "\n",
    "   Решая линейное уравнение\n",
    "   $\\;F(x_n) + F'(x_n)(x - x_n)=0$,\n",
    "   получаем новое приближение\n",
    "\n",
    "   $$\n",
    "   x_{n+1} = x_n - \\frac{F(x_n)}{F'(x_n)}.\n",
    "   $$\n",
    "\n",
    "2. **Условия применимости.**\n",
    "\n",
    "   * $F$ должна быть дифференцируема около корня.\n",
    "   * В окрестности решения $F'(x)\\neq0$ (иначе касательная горизонтальна и не пересекает ось абсцисс).\n",
    "\n",
    "3. **Выбор начального приближения.**\n",
    "   Чем ближе $x_0$ к истинному корню, тем быстрее и надёжнее сходится метод.\n",
    "   Чтобы гарантировать сходимость, часто выбирают $x_0$ так, чтобы на отрезке $[a,b]$, где лежит корень:\n",
    "\n",
    "   * $F$, $F'$ и $F''$ сохраняют знак (монотонность и «выпуклость» не меняются).\n",
    "   * Начальное $x_0$ берут в том конце отрезка, где одновременно одинаковы знаки $F(x)$ и $F''(x)$.\n",
    "\n",
    "4. **Скорость сходимости.**\n",
    "   При условии «хорошего» приближения (когда высшие члены Тейлора малы) ошибка $\\delta_n = x_n - x^*$ убывает по квадратичному закону:\n",
    "\n",
    "   $$\n",
    "   \\delta_{n+1} \\approx C\\,\\delta_n^2,\n",
    "   $$\n",
    "\n",
    "   что означает **очень быструю** (квадратичную) сходимость.\n",
    "\n",
    "5. **Метод Ньютона как частный случай простой итерации.**\n",
    "   Общая простая итерация:\n",
    "\n",
    "   $$\n",
    "   x = \\varphi(x),\\quad x_{n+1}=\\varphi(x_n).\n",
    "   $$\n",
    "\n",
    "   Если выбрать\n",
    "   $\\;\\varphi(x)=x - \\tfrac{F(x)}{F'(x)}$,\n",
    "   то именно получим метод Ньютона. При этом $\\varphi'(x^*)=0$, что обеспечивает максимальную скорость сходимости.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Обобщение на систему уравнений\n",
    "\n",
    "Рассмотрим систему\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "F_1(x_1,\\dots,x_N)=0,\\\\\n",
    "\\quad\\vdots\\\\\n",
    "F_N(x_1,\\dots,x_N)=0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Шаги метода:\n",
    "\n",
    "1. **Начальное приближение** $\\mathbf x^{(0)}=(x_1^{(0)},\\dots,x_N^{(0)})$.\n",
    "2. **Линейное приближение.** Выписываем первый порядок Тейлора для всех $F_i$:\n",
    "\n",
    "   $$\n",
    "   F_i(\\mathbf x^{(n)}) + \\sum_{j=1}^N \\frac{\\partial F_i}{\\partial x_j}(\\mathbf x^{(n)})\\;\\Delta x_j = 0.\n",
    "   $$\n",
    "3. **Матрица Якоби** $J_{ij}=\\frac{\\partial F_i}{\\partial x_j}$.\n",
    "   Решаем линейную систему\n",
    "\n",
    "   $$\n",
    "   J(\\mathbf x^{(n)})\\;\\Delta \\mathbf x = -\\,\\mathbf F(\\mathbf x^{(n)}).\n",
    "   $$\n",
    "4. **Обновление** $\\mathbf x^{(n+1)}=\\mathbf x^{(n)}+\\Delta\\mathbf x$.\n",
    "5. **Критерий сходимости**: норма вектора поправок $\\|\\Delta\\mathbf x\\|$ меньше заданного $\\varepsilon$.\n",
    "6. **Повторять**, пока $\\|\\Delta\\mathbf x\\|>\\varepsilon$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Примеры\n",
    "\n",
    "### Пример 1. Одномерное уравнение\n",
    "\n",
    "$$\n",
    "F(x)=x^2-2=0\n",
    "$$\n",
    "\n",
    "**Решение:**\n",
    "\n",
    "1. $F'(x)=2x$.\n",
    "2. Итерационная формула:\n",
    "\n",
    "   $$\n",
    "   x_{n+1} = x_n - \\frac{x_n^2-2}{2x_n} \n",
    "           = \\frac12\\Bigl(x_n + \\frac{2}{x_n}\\Bigr).\n",
    "   $$\n",
    "3. Возьмём $x_0=1$.\n",
    "\n",
    "   * $n=0$: $x_1 = \\tfrac12(1 + 2/1)=1.5$.\n",
    "   * $n=1$: $x_2 = \\tfrac12(1.5 + 2/1.5)\\approx1.4167$.\n",
    "   * $n=2$: $x_3\\approx1.4142$.\n",
    "     Уже на третьем шаге достигаем точности порядка $10^{-4}$.\n",
    "\n",
    "### Пример 2. Система из двух уравнений\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "F_1(x,y) = x^2 + y^2 - 5 = 0,\\\\\n",
    "F_2(x,y) = x\\,y - 1 = 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1. **Якобиан**\n",
    "\n",
    "   $$\n",
    "   J=\\begin{pmatrix}\n",
    "   2x & 2y\\\\\n",
    "   y  & x\n",
    "   \\end{pmatrix}.\n",
    "   $$\n",
    "2. Начальное приближение $(x_0,y_0)=(2,1)$.\n",
    "3. Вычисляем\n",
    "   $\\;\\mathbf F(2,1)=\\bigl(2^2+1^2-5,\\;2\\cdot1-1\\bigr)=(0,1)$.\n",
    "   Якобиан в точке $(2,1)$:\n",
    "   $\\;J=\\begin{pmatrix}4&2\\\\1&2\\end{pmatrix}.$\n",
    "4. Решаем линейную систему\n",
    "\n",
    "   $$\n",
    "   \\begin{pmatrix}4&2\\\\1&2\\end{pmatrix}\n",
    "   \\begin{pmatrix}\\Delta x\\\\\\Delta y\\end{pmatrix}\n",
    "   =-\\begin{pmatrix}0\\\\1\\end{pmatrix}.\n",
    "   $$\n",
    "\n",
    "   Получаем, например, $(\\Delta x,\\Delta y)=(-\\tfrac14,\\;\\tfrac18)$.\n",
    "5. Новая точка\n",
    "   $(x_1,y_1)=(2-0.25,\\;1+0.125)=(1.75,\\;1.125)$.\n",
    "6. Повторяя, мы быстро стягиваемся к решению примерно $(\\sqrt5,\\;1/\\sqrt5)\\approx(2.236,0.447)$.\n",
    "\n",
    "---\n",
    "\n",
    "Таким образом, метод Ньютона в одномерном случае даёт очень быструю (квадратичную) сходимость при хорошем выборе $x_0$, а в многомерном сводится к решению линейной системы на каждом шаге с использованием матрицы Якоби.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b513370",
   "metadata": {},
   "source": [
    "<h1>7 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf5569",
   "metadata": {},
   "source": [
    "**Билет 7.**\n",
    "Решение нелинейного уравнения методом Ньютона. Условия применимости. Выбор начального приближения. Достаточное условие сходимости. Скорость сходимости. Метод Ньютона как частный случай простой итерации. Обобщение метода Ньютона на случай системы нелинейных уравнений.\n",
    "\n",
    "---\n",
    "\n",
    "### Краткая «шпаргалка»\n",
    "\n",
    "1. **Формула итерации (одномерный случай):**\n",
    "\n",
    "   $$\n",
    "   x_{n+1} = x_n - \\frac{F(x_n)}{F'(x_n)}.\n",
    "   $$\n",
    "\n",
    "2. **Условия применимости:**\n",
    "\n",
    "   * $F$ непрерывно дифференцируема в окрестности корня.\n",
    "   * $F'(x)\\neq0$ на этом отрезке.\n",
    "\n",
    "3. **Выбор начального приближения $x_0$:**\n",
    "\n",
    "   * Ближе к действительному корню → быстрее сходимость.\n",
    "   * Часто берут край отрезка $[a,b]$, где $F(a)\\,F''(a)>0$ (или то же в $b$).\n",
    "\n",
    "4. **Сходимость и её скорость:**\n",
    "\n",
    "   * Квадратичная: ошибка $\\delta_{n+1}\\approx C\\,\\delta_n^2$.\n",
    "   * Гарантируется при «хорошей» гладкости $F$ и малой начальной ошибке.\n",
    "\n",
    "5. **Как частный случай простой итерации:**\n",
    "   $\\varphi(x)=x - F(x)/F'(x)$, причём $\\varphi'(x^*)=0$.\n",
    "\n",
    "6. **Обобщение на систему $ \\mathbf F(\\mathbf x)=\\mathbf0$:**\n",
    "\n",
    "   * Якобиан $J_{ij}=\\partial F_i/\\partial x_j$.\n",
    "   * На каждом шаге решаем\n",
    "\n",
    "     $$\n",
    "       J(\\mathbf x^{(n)})\\;\\Delta\\mathbf x = -\\,\\mathbf F(\\mathbf x^{(n)}),\n",
    "     $$\n",
    "\n",
    "     после чего $\\mathbf x^{(n+1)}=\\mathbf x^{(n)}+\\Delta\\mathbf x$.\n",
    "   * Критерий остановки: $\\|\\Delta\\mathbf x\\|<\\varepsilon$.\n",
    "\n",
    "---\n",
    "\n",
    "**Конец шпаргалки.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d9b5f",
   "metadata": {},
   "source": [
    "<h1>8 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a45374",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 8. Интерполяция таблично заданной функции**\n",
    "\n",
    "1. **Постановка задачи интерполяции.**\n",
    "   • Даны узлы интерполяции $(x_i, y_i)$, где $y_i = f(x_i)$ и все $x_i$ различны и упорядочены.\n",
    "   • Требуется построить функцию-оценку $F(x)$, такую что $F(x_i)=y_i$ для всех узлов, а для $x$ между узлами считать $F(x)\\approx f(x)$.&#x20;\n",
    "\n",
    "2. **Единственность интерполяционного многочлена.**\n",
    "   • Существует ровно один многочлен $P_n(x)$ степени не выше $n$, который проходит через все $n+1$ узлов.\n",
    "   • Доказательство опирается на невырожденность системы с матрицей Вандермонда, определитель которой отличен от нуля при разных $x_i$.&#x20;\n",
    "\n",
    "3. **Форма Лагранжа.**\n",
    "   • Многочлен $P_n(x)$ удобно записать через базисные многочлены\n",
    "\n",
    "   $$\n",
    "     L_k(x)=\\prod_{j\\neq k}\\frac{x - x_j}{x_k - x_j}, \n",
    "     \\quad P_n(x)=\\sum_{k=0}^n y_k\\,L_k(x).\n",
    "   $$\n",
    "\n",
    "   • В узле $x_i$ все $L_k$ обращаются в ноль, кроме $L_i(x_i)=1$, что обеспечивает автоматическое выполнение условий интерполяции.&#x20;\n",
    "\n",
    "4. **Выражение для ошибки интерполяции (остаточный член).**\n",
    "   • Если $f$ имеет непрерывную $(n+1)$-ю производную на отрезке, то при любом $x$ найдётся $\\xi$ «между» узлами, для которой\n",
    "\n",
    "   $$\n",
    "     r_n(x)=f(x)-P_n(x)\n",
    "     =\\frac{f^{(n+1)}(\\xi)}{(n+1)!}\\,\\prod_{i=0}^n(x-x_i).\n",
    "   $$\n",
    "\n",
    "   • Это выражение даёт представление о том, как растёт погрешность в зависимости от расположения узлов и гладкости $f$.&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "**Примеры решения.**\n",
    "\n",
    "1. **Линейная интерполяция ($n=1$) для $f(x)=x^2$.**\n",
    "   Узлы: $(1,1)$, $(2,4)$.\n",
    "\n",
    "   $$\n",
    "     P_1(x)=1\\cdot\\frac{x-2}{1-2}+4\\cdot\\frac{x-1}{2-1}\n",
    "            =- (x-2)+4(x-1)=2x-2.\n",
    "   $$\n",
    "\n",
    "   Ошибка в точке $x=1.5$:\n",
    "\n",
    "   $$\n",
    "     r_1(1.5)=1.5^2 - (2\\cdot1.5-2)=2.25-1=1.25,\n",
    "     \\quad \\omega_2(1.5)=(1.5-1)(1.5-2)= -0.25.\n",
    "   $$\n",
    "\n",
    "2. **Кубическая интерполяция ($n=3$) для $f(x)=\\sin x$.**\n",
    "   Узлы: $x_0=0,\\;x_1=\\tfrac\\pi6,\\;x_2=\\tfrac\\pi3,\\;x_3=\\tfrac\\pi2$.\n",
    "   По формуле Лагранжа строим $P_3(x)$, а затем оцениваем, например, $P_3(\\pi/4)\\approx \\sin(\\pi/4)=0.7071$.\n",
    "   Остаточный член оценим через $\\max|f^{(4)}(\\xi)|=|\\sin\\xi|\\le1$ и $\\omega_4(\\pi/4)=\\prod_{i=0}^3(\\pi/4-x_i)$.\n",
    "\n",
    "Какой пример интерполяции вам показался более понятным и интересным?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da2fc3",
   "metadata": {},
   "source": [
    "<h1>8 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378312c2",
   "metadata": {},
   "source": [
    "**Шпаргалка по билет № 8 «Интерполяция таблично заданной функции»**\n",
    "\n",
    "1. **Цель:**\n",
    "   – Построить многочлен $P_n(x)$ степени ≤ $n$, проходящий через данные узлы $(x_i,y_i)$.\n",
    "\n",
    "2. **Единственность:**\n",
    "   – Для $n+1$ разных точек такой многочлен единственный (матрица Вандермонда невырождена).\n",
    "\n",
    "3. **Форма Лагранжа:**\n",
    "\n",
    "   $$\n",
    "     P_n(x)=\\sum_{k=0}^n y_k\\;L_k(x), \n",
    "     \\quad\n",
    "     L_k(x)=\\prod_{j\\neq k}\\frac{x - x_j}{x_k - x_j}.\n",
    "   $$\n",
    "\n",
    "4. **Условия:**\n",
    "   – $P_n(x_i)=y_i$ благодаря свойству $L_k(x_i)=\\delta_{ik}$.\n",
    "\n",
    "5. **Остаточный член (ошибка):**\n",
    "\n",
    "   $$\n",
    "     r_n(x)=f(x)-P_n(x)\n",
    "     =\\frac{f^{(n+1)}(\\xi)}{(n+1)!}\\;\\prod_{i=0}^n(x - x_i),\n",
    "     \\quad \\xi\\in[\\min x_i,\\max x_i].\n",
    "   $$\n",
    "\n",
    "6. **Краткий алгоритм ответа на экзамене:**\n",
    "\n",
    "   1. Определить узлы и степень $n$.\n",
    "   2. Сказать про единственность (Вандермонд).\n",
    "   3. Записать формулу Лагранжа.\n",
    "   4. Объяснить $L_k(x_i)$.\n",
    "   5. Упомянуть формулу ошибки.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293c00e",
   "metadata": {},
   "source": [
    "<h1>9 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5cea2",
   "metadata": {},
   "source": [
    "**Экзаменационный билет № 9. Интерполяция таблично заданной функции. Сходимость интерполяции. Теоремы Фабера и Марцинкевича. Свойства многочленов Чебышёва.**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Постановка задачи и виды сходимости\n",
    "\n",
    "* **Интерполяция** — это построение многочлена $P_n(x)$ степени ≤ $n$, который в узлах $\\{x_i\\}_{i=0}^n$ точно воспроизводит заданные значения $f(x_i)$.\n",
    "* **Сходимость процесса** означает, что при $n\\to\\infty$ (и соответствующем выборе узлов) погрешность\n",
    "\n",
    "  $$\n",
    "    r_n(x)=f(x)-P_n(x)\n",
    "  $$\n",
    "\n",
    "  стремится к нулю.\n",
    "* Различают **точечную сходимость** (для каждого фиксированного $x$) и **равномерную сходимость** на отрезке $[a,b]$, когда\n",
    "  $\\max_{x\\in[a,b]}|r_n(x)|\\to0$ при $n\\to\\infty$. На сходимость влияет не только число узлов, но и их распределение по отрезку .\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Теорема Фабера\n",
    "\n",
    "* **Утверждение:** для **любой** заранее выбранной схемы расположения узлов на $[a,b]$ найдётся непрерывная функция $f$, для которой интерполяционные многочлены **не** сходятся равномерно к $f$ на всём отрезке.\n",
    "* **Вывод:** не существует единой «универсальной» сетки, подходящей для **всех** функций .\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Теорема Марцинкевича\n",
    "\n",
    "* **Утверждение:** для **каждой конкретной** функции $f$ можно подобрать такую последовательность сеток, что интерполяционный процесс будет сходиться равномерно на всём отрезке.\n",
    "* **Ключевой пример:** для функции Рунге $f(x)=1/(1+25x^2)$ равномерная сходимость достигается при выборе узлов в виде **корней многочленов Чебышёва** на $[-1,1]$ .\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Многочлены Чебышёва $T_n(x)$ и их свойства\n",
    "\n",
    "1. **Рекуррентное определение:**\n",
    "\n",
    "   $$\n",
    "     T_0(x)=1,\\quad T_1(x)=x,\\quad\n",
    "     T_{n+1}(x)=2x\\,T_n(x)-T_{n-1}(x).\n",
    "   $$\n",
    "\n",
    "2. **Тригонометрическое представление:**\n",
    "\n",
    "   $$\n",
    "     T_n(x)=\\cos\\bigl(n\\arccos x\\bigr),\n",
    "     \\qquad x\\in[-1,1].\n",
    "   $$\n",
    "\n",
    "3. **Корни многочленов:**\n",
    "\n",
    "   $$\n",
    "     x_k=\\cos\\!\\Bigl(\\tfrac{2k+1}{2n}\\pi\\Bigr),\\quad\n",
    "     k=0,1,\\dots,n-1.\n",
    "   $$\n",
    "\n",
    "   Эти узлы равномерно «сжимают» интервалы к краям, минимизируя максимальную величину полинома\n",
    "   $\\omega_{n+1}(x)=\\prod_{i=0}^n(x-x_i)$ (принцип минимакса) .\n",
    "\n",
    "4. **Оптимальность для интерполяции:**\n",
    "   — Распределение корней $T_n$ обеспечивает наименьшую максимальную погрешность при интерполяции на $[-1,1]$.\n",
    "   — Для произвольного отрезка $[a,b]$ достаточно линейно преобразовать корни $[−1,1]$ в точки $[a,b]$ .\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Примеры\n",
    "\n",
    "1. **Разбегание на равномерных узлах (функция Рунге):**\n",
    "\n",
    "   $$\n",
    "     f(x)=\\frac1{1+25x^2},\\quad x\\in[-1,1].\n",
    "   $$\n",
    "\n",
    "   При ровных узлах интерполяционные многочлены быстро «гуляют» у краёв отрезка (эффект Рунге): погрешность растёт при $n\\to\\infty$ .\n",
    "\n",
    "2. **Сходимость на узлах Чебышёва (та же функция):**\n",
    "   Выбираем узлы $x_k=\\cos\\!\\bigl((2k+1)\\pi/2n\\bigr)$. Интерполяция полиномами тех же степеней стабильно приближает $f(x)$ и $ \\max|r_n(x)|\\to0$ равномерно на всём $[-1,1]$ .\n",
    "\n",
    "---\n",
    "\n",
    "Таким образом, **ключ к успешной интерполяции** — не просто увеличить число узлов, а грамотно их разместить: теорема Фабера предупреждает об опасностях равномерных сеток, а сетка Чебышёва, благодаря свойствам $T_n(x)$, реализует идею Марцинкевича, обеспечивая равномерную сходимость.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a53924",
   "metadata": {},
   "source": [
    "<h1>9 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec3521",
   "metadata": {},
   "source": [
    "**Расширенная шпаргалка по билет № 9 «Интерполяция. Сходимость. Фабер. Марцинкевич. Чебышёвы»**\n",
    "\n",
    "1. **Цель и единственность:**\n",
    "   – Нужно найти многочлен $P_n(x)$ степени ≤ $n$, который в узлах $\\{x_i\\}$ точно даёт значения $f(x_i)$.\n",
    "   – Единственность гарантируется невырожденностью матрицы Вандермонда.\n",
    "\n",
    "2. **Виды сходимости:**\n",
    "   – *Точечная*: при любом фиксированном $x$, $P_n(x)\\to f(x)$ по мере роста $n$.\n",
    "   – *Равномерная*: $\\max_{x\\in[a,b]}|P_n(x)-f(x)|\\to0$; зависит от выбора узлов.\n",
    "\n",
    "3. **Теорема Фабера:**\n",
    "   – Для любой заранее заданной схемы узлов найдётся хотя бы одна «плохая» функция $f$, для которой равномерная сходимость не выполняется.\n",
    "   – Это означает: нельзя одним универсальным способом размещать узлы для всех функций.\n",
    "\n",
    "4. **Теорема Марцинкевича:**\n",
    "   – Для каждой конкретной функции $f\\in C[a,b]$ можно подобрать свою, «адаптивную» сетку узлов, обеспечивающую равномерную сходимость.\n",
    "\n",
    "5. **Роль многочленов Чебышёва:**\n",
    "   – Узлы по формулам\n",
    "   $\\displaystyle x_k=\\cos\\!\\bigl(\\tfrac{2k+1}{2n+2}\\pi\\bigr)$ на $[-1,1]$\n",
    "   минимизируют максимум модуля $\\omega_{n+1}(x)=\\prod(x-x_i)$.\n",
    "   – При такой сетке погрешность интерполяции растёт наиболее медленно (минимакс-принцип).\n",
    "\n",
    "6. **Краткий алгоритм ответа:**\n",
    "\n",
    "   1. Обозначить задачу (найти $P_n$, единственность).\n",
    "   2. Описать точечную и равномерную сходимость.\n",
    "   3. Сформулировать обе теоремы (Фабера «против», Марцинкевича «за»).\n",
    "   4. Показать формулу узлов Чебышёва и объяснить их оптимальность.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dafce1",
   "metadata": {},
   "source": [
    "<h1>10 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65f5d4",
   "metadata": {},
   "source": [
    "### Экзаменационный билет: Кубические сплайны\n",
    "\n",
    "#### 1. **Недостатки интерполяции многочленами**\n",
    "Интерполяция многочленами (например, полиномом Лагранжа) имеет два ключевых недостатка:\n",
    "- **Жёсткая связь степени и количества узлов**:  \n",
    "  Для $n+1$ точек требуется многочлен степени $n$. При больших $n$ полиномы становятся неустойчивыми: возникают сильные колебания (эффект Рунге), особенно на краях интервала.  \n",
    "  *Пример*: Для 10 точек степень полинома — 9. Такой полином может давать дикие осцилляции между узлами, даже если исходная функция гладкая.\n",
    "\n",
    "- **Нелокальность**:  \n",
    "  Изменение значения в одном узле влияет на поведение полинома *на всём интервале*. Это неудобно, если данные имеют локальные особенности.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Понятие сплайна**\n",
    "**Сплайн** — кусочно-полиномиальная функция, \"склеенная\" из отрезков многочленов низкой степени.  \n",
    "- **Ключевые свойства**:  \n",
    "  - Непрерывность самой функции и её производных (до определённого порядка) в узлах.  \n",
    "  - Степень сплайна *не зависит* от количества узлов (можно строить сплайн 3-й степени для 100 точек).  \n",
    "- **Почему \"сплайн\"?**  \n",
    "  Термин происходит от гибкой чертёжной рейки (англ. *spline*), которая под действием упругости принимает форму с минимальной кривизной, проходя через заданные точки. Математически это соответствует *кубическому сплайну*.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Построение кубического сплайна**\n",
    "Кубический сплайн $S(x)$ состоит из сегментов-кубиков на каждом интервале $[x_i, x_{i+1}]$:  \n",
    "$\n",
    "s_i(x) = A_i + B_i x + C_i x^2 + D_i x^3.\n",
    "$\n",
    "\n",
    "**Условия для определения коэффициентов**:  \n",
    "1. **Интерполяция**: $s_i(x_i) = f_i$, $s_i(x_{i+1}) = f_{i+1}$.  \n",
    "2. **Непрерывность производных**:  \n",
    "   - $s'_{i-1}(x_i) = s'_i(x_i)$ (гладкость \"без изломов\"),  \n",
    "   - $s''_{i-1}(x_i) = s''_i(x_i)$ (плавность кривизны).  \n",
    "\n",
    "**Проблема**: Условия дают $4n-2$ уравнений, но коэффициентов $4n$ → нужно ещё **2 граничных условия**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Типы граничных условий**\n",
    "- **Естественный сплайн**: $s''(x_0) = s''(x_n) = 0$ (рейка \"свободна\" на концах).  \n",
    "- **Not-a-knot**: $s_0'''(x_1) = s_1'''(x_1)$, $s_{n-2}'''(x_{n-1}) = s_{n-1}'''(x_{n-1})$ (первые и последние сегменты \"сливаются\").  \n",
    "- **Clamped**: $s'(x_0) = s'(x_n) = 0$ (закреплённые концы).  \n",
    "- **Периодический**: $s'(x_0) = s'(x_n)$, $s''(x_0) = s''(x_n)$.  \n",
    "\n",
    "> **Важно!** Естественный сплайн не всегда даёт лучшее приближение — его кривизна может быть слишком большой у границ.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Практическая реализация**\n",
    "Чтобы упростить расчёты, сплайн удобно записать в форме:  \n",
    "$\n",
    "s_i(x) = f_i + b_i(x - x_i) + c_i(x - x_i)^2 + d_i(x - x_i)^3.\n",
    "$  \n",
    "**Смысл коэффициентов**:  \n",
    "- $b_i = s_i'(x_i)$ (первая производная),  \n",
    "- $c_i = \\frac{s_i''(x_i)}{2}$ (половина второй производной),  \n",
    "- $d_i = \\frac{s_i'''(x_i)}{6}$ (шестая часть третьей производной).  \n",
    "\n",
    "**Алгоритм**:  \n",
    "1. Решить систему уравнений для $\\sigma_i = \\frac{s_i''(x_i)}{6}$ (трёхдиагональная матрица).  \n",
    "2. Вычислить $b_i, c_i, d_i$ через $\\sigma_i$.  \n",
    "\n",
    "---\n",
    "\n",
    "### Примеры\n",
    "#### Пример 1: Простой случай (3 точки)\n",
    "**Дано**:  \n",
    "Узлы: $x = [0, 1, 2]$, $f = [1, 3, 2]$.  \n",
    "Граничные условия: *естественный сплайн* ($s''(0) = s''(2) = 0$).  \n",
    "\n",
    "**Решение**:  \n",
    "1. Сегмент $s_0(x)$ на $[0,1]$: $s_0(x) = 1 + b_0 x + c_0 x^2 + d_0 x^3$.  \n",
    "2. Сегмент $s_1(x)$ на $[1,2]$: $s_1(x) = 3 + b_1(x-1) + c_1(x-1)^2 + d_1(x-1)^3$.  \n",
    "3. Условия:  \n",
    "   - $s_0(1) = 3$ → $1 + b_0 + c_0 + d_0 = 3$,  \n",
    "   - $s_1(2) = 2$ → $3 + b_1 + c_1 + d_1 = 2$,  \n",
    "   - Непрерывность производных в $x=1$:  \n",
    "     $\n",
    "     s_0'(1) = s_1'(1) \\Rightarrow b_0 + 2c_0 + 3d_0 = b_1,  \n",
    "     $  \n",
    "     $\n",
    "     s_0''(1) = s_1''(1) \\Rightarrow 2c_0 + 6d_0 = 2c_1.  \n",
    "     $  \n",
    "   - Граничные: $s_0''(0) = 0 \\Rightarrow 2c_0 = 0$, $s_1''(2) = 0 \\Rightarrow 2c_1 + 6d_1 = 0$.  \n",
    "\n",
    "**Результат**:  \n",
    "$c_0 = 0$, $c_1 = -3$, $d_0 = 2$, $d_1 = 1$, $b_0 = 3$, $b_1 = -4$.  \n",
    "$\n",
    "s_0(x) = 1 + 3x + 2x^3, \\quad s_1(x) = 3 -4(x-1) -3(x-1)^2 + (x-1)^3.\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример 2: Сравнение с полиномом Лагранжа\n",
    "**Дано**:  \n",
    "Точки: $(0,0), (1,1), (2,0), (3,1)$.  \n",
    "\n",
    "- **Полином Лагранжа** (степень 3):  \n",
    "  $\n",
    "  P_3(x) = -\\frac{x^3}{2} + \\frac{5x^2}{2} - 3x.\n",
    "  $  \n",
    "  На интервале $[0,3]$ он осциллирует (например, в $x=1.5$: $P_3(1.5) = -0.375$, хотя данные идут от 0 до 1).  \n",
    "\n",
    "- **Кубический сплайн** (границы *not-a-knot*):  \n",
    "  Сегменты гладко соединяются, кривая следует за данными без выбросов.  \n",
    "  *Результат для $x=1.5$*: $s \\approx 0.8$ (логично между 0 и 1).  \n",
    "\n",
    "---\n",
    "\n",
    "### Итог\n",
    "**Преимущества сплайнов**:  \n",
    "1. **Устойчивость**: Нет осцилляций при большом числе точек.  \n",
    "2. **Локальность**: Изменение данных в одном узле влияет только на соседние сегменты.  \n",
    "3. **Гладкость**: Непрерывность второй производной обеспечивает плавность кривой.  \n",
    "4. **Гибкость**: Разные граничные условия адаптируют сплайн под физику задачи.  \n",
    "\n",
    "**Применение**:  \n",
    "Чертёжные работы, моделирование траекторий, компьютерная графика, обработка экспериментальных данных (например, термодинамика: расчёт теплоты по табличным значениям теплоёмкости)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fe0fd",
   "metadata": {},
   "source": [
    "<h1>10 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de348c",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет: Кубические сплайны  \n",
    "**(Краткая шпаргалка)**  \n",
    "\n",
    "#### 1. **Недостатки интерполяции многочленами**  \n",
    "- **Высокая степень полинома**: Для $n+1$ точек → полином степени $n$.  \n",
    "- **Осцилляции**: Сильные колебания между узлами (эффект Рунге).  \n",
    "- **Глобальное влияние**: Изменение одной точки меняет весь полином.  \n",
    "\n",
    "#### 2. **Сплайн — определение**  \n",
    "- Кусочно-полиномиальная функция степени $k$ (чаще $k=3$).  \n",
    "- **Свойства**:  \n",
    "  - Непрерывность $S(x)$, $S'(x)$, $S''(x)$ в узлах.  \n",
    "  - Степень не зависит от числа узлов.  \n",
    "\n",
    "#### 3. **Кубический сплайн**  \n",
    "- **Сегменты**: На $[x_i, x_{i+1}]$:  \n",
    "  $\n",
    "  s_i(x) = a_i + b_i(x - x_i) + c_i(x - x_i)^2 + d_i(x - x_i)^3.\n",
    "  $  \n",
    "- **Условия**:  \n",
    "  - Интерполяция: $s_i(x_i) = f_i$, $s_i(x_{i+1}) = f_{i+1}$.  \n",
    "  - Склейка: В узлах $x_i$ ($i=1,...,n-1$):  \n",
    "    $\n",
    "    s_{i-1}'(x_i) = s_i'(x_i), \\quad s_{i-1}''(x_i) = s_i''(x_i).\n",
    "    $  \n",
    "- **Граничные условия** (2 доп. уравнения):  \n",
    "  - **Естественный**: $s''(x_0) = s''(x_n) = 0$.  \n",
    "  - **Not-a-knot**: $s_0'''(x_1) = s_1'''(x_1)$, $s_{n-2}'''(x_{n-1}) = s_{n-1}'''(x_n)$.  \n",
    "  - **Clamped**: $s'(x_0) = A$, $s'(x_n) = B$ (часто $A=B=0$).  \n",
    "\n",
    "#### 4. **Алгоритм построения**  \n",
    "1. Решить СЛАУ для $\\sigma_i = \\frac{s_i''(x_i)}{6}$ (трёхдиагональная матрица).  \n",
    "2. Вычислить коэффициенты:  \n",
    "   $\n",
    "   b_i = \\Delta_i - h_i(\\sigma_{i+1} + 2\\sigma_i), \\quad c_i = 3\\sigma_i, \\quad d_i = \\frac{\\sigma_{i+1} - \\sigma_i}{h_i}.\n",
    "   $  \n",
    "\n",
    "#### 5. **Преимущества перед полиномами**  \n",
    "- **Устойчивость**: Нет осцилляций.  \n",
    "- **Локальность**: Изменение точки влияет только на соседние сегменты.  \n",
    "- **Гладкость**: $C^2$-непрерывность (плавность кривой).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51932d47",
   "metadata": {},
   "source": [
    "<h1>11 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4499107",
   "metadata": {},
   "source": [
    "### Экзаменационный билет:  \n",
    "**Суммарная погрешность численного дифференцирования и её составляющие: ошибка дискретизации (усечения) и ошибка округления. Оптимальный выбор шага.**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Суть проблемы**  \n",
    "При численном дифференцировании мы заменяем точную производную $ f'(x) $ приближённой формулой, например:  \n",
    "$\n",
    "f'(x) \\approx \\frac{f(x+h) - f(x)}{h} \\quad \\text{(простейшая формула)}.\n",
    "$  \n",
    "Здесь возникает **два типа погрешностей**:  \n",
    "- **Ошибка усечения (дискретизации)** $\\delta_t$ — из-за отбрасывания старших членов ряда Тейлора.  \n",
    "- **Ошибка округления** $\\delta_r$ — из-за ограниченной точности вычислений значений функции.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Составляющие погрешности**  \n",
    "#### (а) Ошибка усечения ($\\delta_t$)  \n",
    "- **Причина**: Замена бесконечно малого приращения аргумента на конечный шаг $ h $.  \n",
    "- **Формула** (для простейшего метода):  \n",
    "$\n",
    "\\delta_t = \\frac{h}{2} f''(x) + \\frac{h^2}{6} f'''(x) + \\cdots\n",
    "$  \n",
    "- **Свойства**:  \n",
    "  - $\\delta_t \\propto h$ (для малых $ h $).  \n",
    "  - Уменьшается при уменьшении $ h $.  \n",
    "\n",
    "#### (б) Ошибка округления ($\\delta_r$)  \n",
    "- **Причина**: При малых $ h $ значения $ f(x) $ и $ f(x+h) $ близки. Их разность вычисляется с большой относительной ошибкой.  \n",
    "- **Формула**:  \n",
    "$\n",
    "\\delta_r \\approx \\frac{2 \\varepsilon |f(x)|}{h},\n",
    "$  \n",
    "где $\\varepsilon$ — относительная погрешность вычисления $ f(x) $ (например, машинный эпсилон $\\sim 10^{-16}$).  \n",
    "- **Свойства**:  \n",
    "  - $\\delta_r \\propto \\frac{1}{h}$.  \n",
    "  - Растёт при уменьшении $ h $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Суммарная погрешность**  \n",
    "$\n",
    "\\delta_{\\text{сум}} = |\\delta_t| + |\\delta_r|.\n",
    "$  \n",
    "- **График зависимости** (см. рис. в лекции):  \n",
    "  - При уменьшении $ h $: $\\delta_t \\downarrow$, но $\\delta_r \\uparrow$.  \n",
    "  - При увеличении $ h $: $\\delta_t \\uparrow$, но $\\delta_r \\downarrow$.  \n",
    "- **Оптимальный шаг $ h_{\\text{opt}} $** находится в точке минимума $\\delta_{\\text{сум}}$ (где $\\delta_t \\approx \\delta_r$).  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Как найти $ h_{\\text{opt}} $?**  \n",
    "Из условия $|\\delta_t| \\approx |\\delta_r|$:  \n",
    "$\n",
    "\\left| \\frac{h}{2} f''(x) \\right| \\approx \\frac{2 \\varepsilon |f(x)|}{h}.\n",
    "$  \n",
    "Решение относительно $ h $:  \n",
    "$\n",
    "h_{\\text{opt}} \\approx 2 \\sqrt{\\varepsilon \\cdot \\left| \\frac{f(x)}{f''(x)} \\right|}.\n",
    "$  \n",
    "**Проблема**: Для расчёта $ h_{\\text{opt}} $ нужно знать $ f''(x) $, которая обычно неизвестна.  \n",
    "**Практика**: Шаг выбирают экспериментально, например:  \n",
    "- Начинают с $ h \\sim 10^{-6} $,  \n",
    "- Уменьшают $ h $ в 10 раз, пока погрешность не начнёт расти.  \n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Как улучшить точность?**  \n",
    "Используют формулы **высокого порядка точности**, например:  \n",
    "$\n",
    "f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h} \\quad \\text{(порядок точности 2)}.\n",
    "$  \n",
    "- **Преимущества**:  \n",
    "  - Ошибка усечения $\\delta_t \\propto h^2$ (убывает быстрее!).  \n",
    "  - Можно брать больший шаг $ h $, уменьшая $\\delta_r$.  \n",
    "  - Оптимальная погрешность $\\delta_{\\text{min}}$ ниже, чем у простейшего метода (см. рис. 3 в лекции).  \n",
    "\n",
    "---\n",
    "\n",
    "### Примеры расчета  \n",
    "#### Пример 1: Функция $ f(x) = x^2 $ в точке $ x = 1 $  \n",
    "- Точная производная: $ f'(1) = 2 $.  \n",
    "- Простейшая формула:  \n",
    "  $\n",
    "  f'(1) \\approx \\frac{(1+h)^2 - 1^2}{h} = \\frac{1 + 2h + h^2 - 1}{h} = 2 + h.\n",
    "  $  \n",
    "  - Ошибка усечения: $\\delta_t = h$.  \n",
    "- Симметричная формула:  \n",
    "  $\n",
    "  f'(1) \\approx \\frac{(1+h)^2 - (1-h)^2}{2h} = \\frac{(1 + 2h + h^2) - (1 - 2h + h^2)}{2h} = \\frac{4h}{2h} = 2.\n",
    "  $  \n",
    "  - Ошибка усечения: $\\delta_t = 0$ (для квадратичной функции).  \n",
    "\n",
    "#### Пример 2: Функция $ f(x) = e^x $ в точке $ x = 0 $  \n",
    "- Точная производная: $ f'(0) = 1 $.  \n",
    "- Пусть $\\varepsilon = 10^{-16}$ (машинный эпсилон).  \n",
    "- Оптимальный шаг для простейшей формулы:  \n",
    "  $\n",
    "  h_{\\text{opt}} \\approx 2 \\sqrt{\\frac{\\varepsilon \\cdot |e^0|}{|e^0|}} = 2 \\sqrt{\\varepsilon} \\approx 2 \\times 10^{-8}.\n",
    "  $  \n",
    "- При $ h = 10^{-8} $:  \n",
    "  - $\\delta_t \\approx \\frac{h}{2} \\cdot 1 = 5 \\times 10^{-9}$,  \n",
    "  - $\\delta_r \\approx \\frac{2 \\varepsilon}{h} = \\frac{2 \\times 10^{-16}}{10^{-8}} = 2 \\times 10^{-8}$.  \n",
    "  - Суммарная погрешность: $\\delta_{\\text{сум}} \\approx 2.5 \\times 10^{-8}$.  \n",
    "- При $ h = 10^{-10} $:  \n",
    "  - $\\delta_t \\approx 5 \\times 10^{-11}$,  \n",
    "  - $\\delta_r \\approx \\frac{2 \\times 10^{-16}}{10^{-10}} = 2 \\times 10^{-6}$ (доминирует!).  \n",
    "\n",
    "---\n",
    "\n",
    "### Итог:  \n",
    "1. **Суммарная погрешность** — компромисс между ошибкой усечения и округления.  \n",
    "2. **Оптимальный шаг** $ h_{\\text{opt}} $ минимизирует $\\delta_{\\text{сум}}$.  \n",
    "3. **Формулы высокого порядка** (например, симметричная) дают лучшую точность при бóльших $ h $.  \n",
    "4. **Не используйте слишком малые $ h \\!$** — это увеличивает ошибку округления!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92413e24",
   "metadata": {},
   "source": [
    "<h1>11 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b621a32",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет:  \n",
    "**Суммарная погрешность численного дифференцирования** складывается из двух компонент:  \n",
    "1. **Ошибка усечения (дискретизации)** $\\delta_t$:  \n",
    "   - Возникает из-за замены производной разностным отношением.  \n",
    "   - Для формулы $f'(x) \\approx \\frac{f(x+h)-f(x)}{h}$: $\\delta_t \\propto h$.  \n",
    "   - Уменьшается при увеличении $h$.  \n",
    "\n",
    "2. **Ошибка округления** $\\delta_r$:  \n",
    "   - Связана с потерей точности при вычитании близких значений $f(x)$ и $f(x+h)$.  \n",
    "   - $\\delta_r \\propto \\frac{\\varepsilon}{h}$, где $\\varepsilon$ — погрешность вычисления $f(x)$.  \n",
    "   - Увеличивается при уменьшении $h$.  \n",
    "\n",
    "**Суммарная погрешность**:  \n",
    "$\n",
    "\\delta_{\\text{сум}} = |\\delta_t| + |\\delta_r|.\n",
    "$  \n",
    "График $\\delta_{\\text{сум}}(h)$ имеет минимум в точке **оптимального шага $h_{\\text{opt}}$**, где $\\delta_t \\approx \\delta_r$.  \n",
    "\n",
    "**Оптимальный шаг**:  \n",
    "$\n",
    "h_{\\text{opt}} \\approx 2 \\sqrt{\\varepsilon \\cdot \\left| \\frac{f(x)}{f''(x)} \\right|}.\n",
    "$  \n",
    "**Практический выбор**:  \n",
    "- Начать с $h \\sim 10^{-6}$,  \n",
    "- Уменьшать $h$ в 10 раз, пока погрешность не начнёт расти.  \n",
    "\n",
    "**Советы**:  \n",
    "- Используйте формулы высокого порядка (например, $\\frac{f(x+h)-f(x-h)}{2h}$), где $\\delta_t \\propto h^2$.  \n",
    "- Избегайте слишком малых $h$ (усиливается $\\delta_r$).  \n",
    "\n",
    "---\n",
    "\n",
    "### Примеры для иллюстрации:  \n",
    "1. **Для $f(x) = x^2$ в $x=1$**:  \n",
    "   - Симметричная формула: $\\frac{(1+h)^2 - (1-h)^2}{2h} = 2$ (точное значение).  \n",
    "\n",
    "2. **Для $f(x) = e^x$ в $x=0$**:  \n",
    "   - При $h = 10^{-8}$: $\\delta_{\\text{сум}} \\approx 2.5 \\times 10^{-8}$,  \n",
    "   - При $h = 10^{-10}$: $\\delta_{\\text{сум}} \\approx 2 \\times 10^{-6}$ (доминирует $\\delta_r$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04ae0a",
   "metadata": {},
   "source": [
    "<h1>12 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bfa52",
   "metadata": {},
   "source": [
    "### Экзаменационный билет: Численное дифференцирование\n",
    "\n",
    "#### 1. **Уточненное дифференцирование. Порядок точности формул дифференцирования**  \n",
    "Численное дифференцирование — это приближенное вычисление производной функции, заданной таблично или аналитически, с помощью конечных разностей.  \n",
    "\n",
    "- **Порядок точности** — максимальная степень многочлена, для которого формула дает точное значение производной.  \n",
    "  - *Пример*: Формула $ f'(x) \\approx \\frac{f(x+h) - f(x)}{h} $ имеет **1-й порядок точности**. Она точна для линейных функций ($ f(x) = ax + b $), но не для квадратичных.  \n",
    "  - Формула $ f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h} $ имеет **2-й порядок точности**. Она точна для квадратичных функций ($ f(x) = x^2 $).  \n",
    "\n",
    "**Почему порядок важен?**  \n",
    "Чем выше порядок, тем быстрее уменьшается погрешность при уменьшении шага $ h $. Например, для 2-го порядка ошибка убывает как $ h^2 $, а для 1-го — как $ h $.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Способы уменьшения суммарной погрешности**  \n",
    "Суммарная погрешность $ \\delta $ складывается из:  \n",
    "- **Ошибки усечения (дискретизации)** $ \\delta_t $:  \n",
    "  Возникает из-за отбрасывания старших членов ряда Тейлора.  \n",
    "  - Для формулы (1): $ \\delta_t \\approx \\frac{h}{2} f''(x) $.  \n",
    "  - Для формулы (6): $ \\delta_t \\approx \\frac{h^2}{6} f'''(x) $.  \n",
    "\n",
    "- **Ошибки округления** $ \\delta_r $:  \n",
    "  Обусловлена неточностью вычисления $ f(x) $ (машинная арифметика).  \n",
    "  $$\n",
    "  \\delta_r \\approx \\frac{2 \\varepsilon |f(x)|}{h}, \\quad \\text{где } \\varepsilon \\text{ — относительная погрешность}.\n",
    "  $$  \n",
    "\n",
    "**Как уменьшить суммарную погрешность?**  \n",
    "1. **Увеличить точность вычислений** (уменьшить $ \\varepsilon $):  \n",
    "   Использовать числа с двойной точностью (`double` вместо `float`).  \n",
    "2. **Выбрать оптимальный шаг $ h $** из условия $ |\\delta_t| \\approx |\\delta_r| $:  \n",
    "   $$\n",
    "   \\frac{2 \\varepsilon |f(x)|}{h} \\approx \\left| \\frac{h}{2} f''(x) \\right| \\implies h \\approx \\sqrt[3]{\\frac{4 \\varepsilon |f(x)|}{|f''(x)|}}.\n",
    "   $$  \n",
    "3. **Использовать формулы высшего порядка точности**:  \n",
    "   Например, формула (6) вместо (1) позволяет увеличить шаг $ h $, уменьшив $ \\delta_r $ без роста $ \\delta_t $.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Вывод формулы произвольного порядка точности**  \n",
    "Формулы строятся на основе **интерполяционного многочлена Лагранжа**.  \n",
    "1. Выбирают узлы $ x_k $ вблизи точки $ x $.  \n",
    "2. Строят многочлен $ P_n(x) $, аппроксимирующий $ f(x) $.  \n",
    "3. Производная $ f'(x) $ заменяется на $ P_n'(x) $:  \n",
    "   $$\n",
    "   f'(x) \\approx \\sum_{k=0}^{n} w_k f(x_k), \\quad w_k = \\frac{dL_k^{(n)}(x)}{dx},\n",
    "   $$  \n",
    "   где $ L_k^{(n)}(x) $ — базисные полиномы Лагранжа.  \n",
    "\n",
    "**Пример для 2-го порядка** (узлы: $ x-h, x, x+h $):  \n",
    "$$\n",
    "w_0 = -\\frac{1}{2h}, \\quad w_1 = 0, \\quad w_2 = \\frac{1}{2h} \\implies f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Формулы для высших производных**  \n",
    "- **Вторая производная** (2-й порядок точности):  \n",
    "  $$\n",
    "  f''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}.\n",
    "  $$  \n",
    "- **Четвертый порядок точности**:  \n",
    "  $$\n",
    "  f''(x) \\approx \\frac{1}{12h^2} \\left[ -f(x-2h) + 16f(x-h) - 30f(x) + 16f(x+h) - f(x+2h) \\right].\n",
    "  $$  \n",
    "\n",
    "---\n",
    "\n",
    "### Примеры расчета  \n",
    "#### Пример 1: Линейная функция $ f(x) = 2x + 1 $  \n",
    "- Точная производная: $ f'(x) = 2 $.  \n",
    "- Формула (1) при $ h = 0.1 $:  \n",
    "  $$\n",
    "  \\frac{f(1.1) - f(1)}{0.1} = \\frac{(2.2 + 1) - (2 + 1)}{0.1} = 2 \\quad (\\text{точный результат}).\n",
    "  $$  \n",
    "- **Почему точно?** Формула 1-го порядка точна для линейных функций.  \n",
    "\n",
    "#### Пример 2: Квадратичная функция $ f(x) = x^2 $  \n",
    "- Точная производная: $ f'(x) = 2x $. В точке $ x = 1 $: $ f'(1) = 2 $.  \n",
    "- Формула (1) при $ h = 0.1 $:  \n",
    "  $$\n",
    "  \\frac{f(1.1) - f(1)}{0.1} = \\frac{1.21 - 1}{0.1} = 2.1 \\quad (\\text{ошибка } 5\\%).\n",
    "  $$  \n",
    "- Формула (6) при $ h = 0.1 $:  \n",
    "  $$\n",
    "  \\frac{f(1.1) - f(0.9)}{0.2} = \\frac{1.21 - 0.81}{0.2} = 2 \\quad (\\text{точный результат}).\n",
    "  $$  \n",
    "- **Вывод:** Формула 2-го порядка точна для квадратичных функций.  \n",
    "\n",
    "#### Пример 3: Влияние ошибок округления  \n",
    "Для $ f(x) = e^x $ при $ x = 0 $:  \n",
    "- Точная производная: $ f'(0) = 1 $.  \n",
    "- Формула (1) при маленьком $ h = 10^{-10} $:  \n",
    "  $$\n",
    "  \\frac{e^{10^{-10}} - e^0}{10^{-10}} \\approx \\frac{(1 + 10^{-10}) - 1}{10^{-10}} = 1,\n",
    "  $$  \n",
    "  но из-за округления $ e^{10^{-10}} \\approx 1 $ (машина считает $ 1.0000000001 - 1 = 0.0000000001 $), что дает:  \n",
    "  $$\n",
    "  \\frac{0.0000000001}{10^{-10}} = 1 \\quad (\\text{ошибка округления незаметна}).\n",
    "  $$  \n",
    "- Если $ h = 10^{-15} $:  \n",
    "  $$\n",
    "  \\frac{e^{10^{-15}} - 1}{10^{-15}} \\approx \\frac{1.000000000000001 - 1}{10^{-15}} = 1,\n",
    "  $$  \n",
    "  но при вычислениях в Python:  \n",
    "  ```python\n",
    "  (math.exp(1e-15) - 1) / 1e-15  # Результат ≈ 1.1102230246251565 (ошибка 11%!)\n",
    "  ```  \n",
    "**Почему?** При $ h \\to 0 $ ошибка округления $ \\delta_r \\sim \\frac{\\varepsilon}{h} $ растет.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449d8d8",
   "metadata": {},
   "source": [
    "<h1>12 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc41ca2",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет:  \n",
    "**Численное дифференцирование**\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Порядок точности формул дифференцирования**  \n",
    "Порядок точности — максимальная степень многочлена, для которого формула даёт точную производную.  \n",
    "- **Формула 1-го порядка**:  \n",
    "  $$\n",
    "  f'(x) \\approx \\frac{f(x+h) - f(x)}{h}\n",
    "  $$  \n",
    "  Точна для линейных функций ($f(x) = ax + b$).  \n",
    "- **Формула 2-го порядка**:  \n",
    "  $$\n",
    "  f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}\n",
    "  $$  \n",
    "  Точна для квадратичных функций ($f(x) = x^2$).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Способы уменьшения суммарной погрешности**  \n",
    "Суммарная погрешность $\\delta = \\delta_t + \\delta_r$:  \n",
    "- $\\delta_t$ (ошибка усечения): уменьшается при $h \\to 0$ или использовании формул высшего порядка.  \n",
    "- $\\delta_r$ (ошибка округления): уменьшается при увеличении $h$ или повышении точности вычислений.  \n",
    "**Оптимальный шаг $h$**: выбирается из условия $|\\delta_t| \\approx |\\delta_r|$, что минимизирует $\\delta$.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Вывод формулы произвольного порядка точности**  \n",
    "1. Выбрать $n+1$ узлов $x_k$ вокруг точки $x$.  \n",
    "2. Построить интерполяционный многочлен Лагранжа $P_n(x)$.  \n",
    "3. Продифференцировать $P_n(x)$:  \n",
    "   $$\n",
    "   f'(x) \\approx \\sum_{k=0}^{n} w_k f(x_k), \\quad w_k = \\frac{dL_k}{dx}(x).\n",
    "   $$  \n",
    "**Пример для 2-го порядка** (узлы $x-h, x, x+h$):  \n",
    "$$\n",
    "w_0 = -\\frac{1}{2h}, \\quad w_1 = 0, \\quad w_2 = \\frac{1}{2h}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Формулы для высших производных**  \n",
    "- **Вторая производная (2-й порядок)**:  \n",
    "  $$\n",
    "  f''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}.\n",
    "  $$  \n",
    "- **Вторая производная (4-й порядок)**:  \n",
    "  $$\n",
    "  f''(x) \\approx \\frac{-f(x-2h) + 16f(x-h) - 30f(x) + 16f(x+h) - f(x+2h)}{12h^2}.\n",
    "  $$  \n",
    "\n",
    "---\n",
    "\n",
    "### Примеры  \n",
    "1. **Для $f(x) = x^2$ в точке $x=1$**:  \n",
    "   - Формула 1-го порядка ($h=0.1$):  \n",
    "     $$\n",
    "     \\frac{(1.1)^2 - 1^2}{0.1} = 2.1 \\quad (\\text{ошибка } 5\\%).\n",
    "     $$  \n",
    "   - Формула 2-го порядка ($h=0.1$):  \n",
    "     $$\n",
    "     \\frac{(1.1)^2 - (0.9)^2}{0.2} = 2 \\quad (\\text{точно}).\n",
    "     $$  \n",
    "\n",
    "2. **Оптимальный шаг $h$**:  \n",
    "   Для $f(x) = e^x$ при малых $h$ ($h < 10^{-10}$) ошибка округления доминирует. Решение: взять $h \\sim \\sqrt[3]{\\varepsilon}$ (например, $h = 10^{-5}$ для $\\varepsilon = 10^{-15}$).  \n",
    "\n",
    "---\n",
    "\n",
    "**Итог**:  \n",
    "- Порядок точности определяет скорость сходимости.  \n",
    "- Оптимальный $h$ балансирует $\\delta_t$ и $\\delta_r$.  \n",
    "- Формулы высших порядков уменьшают погрешность без уменьшения $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296a463",
   "metadata": {},
   "source": [
    "<h1>13 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3935d",
   "metadata": {},
   "source": [
    "### Экзаменационный билет: Численное интегрирование  \n",
    "**Тема:** Построение квадратурных формул, формулы Ньютона-Котеса (трапеций, Симпсона, Ньютона), веса узлов, погрешность.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Общий принцип построения квадратурных формул  \n",
    "**Цель:** Приближенно вычислить интеграл $\\int_a^b f(x)  dx$.  \n",
    "**Алгоритм:**  \n",
    "1. **Выбрать узлы** на $[a, b]$: $x_0, x_1, \\ldots, x_n$ (часто равноотстоящие).  \n",
    "2. **Построить интерполяционный многочлен $P_n(x)$** степени $n$, проходящий через значения $f(x_k)$ в узлах.  \n",
    "3. **Проинтегрировать $P_n(x)$** вместо $f(x)$:  \n",
    "   $$\n",
    "   \\int_a^b f(x)  dx \\approx \\int_a^b P_n(x)  dx = \\sum_{k=0}^n w_k f(x_k),\n",
    "   $$  \n",
    "   где **веса $w_k$** вычисляются как:  \n",
    "   $$\n",
    "   w_k = \\int_a^b L_k(x)  dx, \\quad L_k(x) = \\prod_{\\substack{i=0 \\\\ i \\neq k}}^n \\frac{x - x_i}{x_k - x_i} \\quad (\\text{базисный многочлен Лагранжа}).\n",
    "   $$  \n",
    "**Итог:** Веса зависят только от расположения узлов, а не от $f(x)$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Формулы Ньютона-Котеса  \n",
    "**Особенности:**  \n",
    "- Узлы **равноотстоящие**, включают концы отрезка: $x_k = a + kh$, $h = \\frac{b-a}{n}$.  \n",
    "- Веса **симметричны** (для $x_k$ и $x_{n-k}$).  \n",
    "\n",
    "#### Формула трапеций ($n=1$)  \n",
    "- **Узлы:** $x_0 = a$, $x_1 = b$.  \n",
    "- **Веса:**  \n",
    "  $$\n",
    "  w_0 = w_1 = \\frac{h}{2}, \\quad h = b - a.\n",
    "  $$  \n",
    "- **Формула:**  \n",
    "  $$\n",
    "  \\int_a^b f(x)  dx \\approx \\frac{h}{2} \\left[ f(a) + f(b) \\right].\n",
    "  $$  \n",
    "- **Погрешность:** $-\\frac{h^3}{12} f''(\\xi)$, $\\xi \\in [a, b]$.\n",
    "\n",
    "#### Формула Симпсона ($n=2$)  \n",
    "- **Узлы:** $x_0 = a$, $x_1 = a + h$, $x_2 = b$, $h = \\frac{b-a}{2}$.  \n",
    "- **Веса:**  \n",
    "  $$\n",
    "  w_0 = w_2 = \\frac{h}{3}, \\quad w_1 = \\frac{4h}{3}.\n",
    "  $$  \n",
    "- **Формула:**  \n",
    "  $$\n",
    "  \\int_a^b f(x)  dx \\approx \\frac{h}{3} \\left[ f(a) + 4f(a+h) + f(b) \\right].\n",
    "  $$  \n",
    "- **Погрешность:** $-\\frac{h^5}{90} f^{(4)}(\\xi)$.\n",
    "\n",
    "#### Формула Ньютона («правило 3/8», $n=3$)  \n",
    "- **Узлы:** $x_0 = a$, $x_1 = a + h$, $x_2 = a + 2h$, $x_3 = b$, $h = \\frac{b-a}{3}$.  \n",
    "- **Веса:**  \n",
    "  $$\n",
    "  w_0 = w_3 = \\frac{3h}{8}, \\quad w_1 = w_2 = \\frac{9h}{8}.\n",
    "  $$  \n",
    "- **Формула:**  \n",
    "  $$\n",
    "  \\int_a^b f(x)  dx \\approx \\frac{3h}{8} \\left[ f(a) + 3f(a+h) + 3f(a+2h) + f(b) \\right].\n",
    "  $$  \n",
    "- **Погрешность:** $-\\frac{3h^5}{80} f^{(4)}(\\xi)$.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Порядок точности  \n",
    "**Определение:** Максимальная степень многочлена, интегрируемого **точно**.  \n",
    "- **Трапеции:** точна для линейных функций (порядок 1).  \n",
    "- **Симпсона:** точна для кубических функций (порядок 3).  \n",
    "- **Ньютона ($n=3$):** точна для кубических функций (порядок 3).  \n",
    "\n",
    "**Важно!**  \n",
    "Формулы с нечётным $n$ имеют тот же порядок точности, что и формулы с $n+1$ узлами. Например, трапеции ($n=1$) и Симпсон ($n=2$) оба имеют порядок 1 для линейных функций, но Симпсон точнее за счёт более высокого порядка погрешности.\n",
    "\n",
    "---\n",
    "\n",
    "### Примеры расчета  \n",
    "#### Пример 1: Формула трапеций для $f(x) = x^2$ на $[0, 1]$  \n",
    "- Точное значение: $\\int_0^1 x^2  dx = \\frac{1}{3} \\approx 0.3333$.  \n",
    "- Шаг $h = 1$:  \n",
    "  $$\n",
    "  \\frac{1}{2} \\left[ f(0) + f(1) \\right] = \\frac{1}{2} \\left[ 0 + 1 \\right] = 0.5.\n",
    "  $$  \n",
    "- Погрешность: $|0.5 - 0.3333| = 0.1667$.  \n",
    "**Объяснение:** Формула трапеций заменяет кривую $x^2$ на прямую, соединяющую $(0,0)$ и $(1,1)$, что даёт завышенный результат.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример 2: Формула Симпсона для $f(x) = x^3$ на $[0, 2]$  \n",
    "- Точное значение: $\\int_0^2 x^3  dx = 4$.  \n",
    "- Узлы: $x_0=0$, $x_1=1$, $x_2=2$, $h=1$.  \n",
    "- Расчет:  \n",
    "  $$\n",
    "  \\frac{1}{3} \\left[ f(0) + 4f(1) + f(2) \\right] = \\frac{1}{3} \\left[ 0 + 4 \\cdot 1 + 8 \\right] = \\frac{12}{3} = 4.\n",
    "  $$  \n",
    "**Итог:** Точное значение, так как формула Симпсона интегрирует кубические функции точно.\n",
    "\n",
    "---\n",
    "\n",
    "#### Пример 3: Формула Ньютона ($n=3$) для $f(x) = \\sin x$ на $[0, \\pi]$  \n",
    "- Точное значение: $\\int_0^\\pi \\sin x  dx = 2$.  \n",
    "- Шаг $h = \\pi/3$:  \n",
    "  Узлы: $x_0=0$, $x_1=\\pi/3$, $x_2=2\\pi/3$, $x_3=\\pi$.  \n",
    "- Расчет:  \n",
    "  $$\n",
    "  \\frac{3h}{8} \\left[ \\sin 0 + 3 \\sin(\\pi/3) + 3 \\sin(2\\pi/3) + \\sin \\pi \\right] = \\frac{3 \\cdot \\pi/3}{8} \\left[ 0 + 3 \\cdot \\frac{\\sqrt{3}}{2} + 3 \\cdot \\frac{\\sqrt{3}}{2} + 0 \\right] = \\frac{\\pi}{8} \\cdot 3\\sqrt{3} \\approx 2.0405.\n",
    "  $$  \n",
    "- Погрешность: $|2.0405 - 2| = 0.0405$.  \n",
    "**Вывод:** Для гладких функций увеличение числа узлов уменьшает погрешность.\n",
    "\n",
    "---\n",
    "\n",
    "### Почему веса такие?  \n",
    "- **Трапеции:** Среднее значений на концах (площадь трапеции).  \n",
    "- **Симпсона:** Учет «веса» средней точки для аппроксимации параболы.  \n",
    "- **Ньютона ($n=3$):** Балансировка вкладов точек для кубической интерполяции.  \n",
    "\n",
    "**Ключевая идея:** Чем выше степень многочлена, используемого в формуле, тем точнее результат для гладких функций, но тем сложнее вычисления. Для больших $n$ ($>9$) формулы Ньютона-Котеса становятся неустойчивыми из-за отрицательных весов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d471fef",
   "metadata": {},
   "source": [
    "<h1>13 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9410cf5",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет: Численное интегрирование  \n",
    "**(Краткая шпаргалка для устного ответа)**\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Общий принцип квадратурных формул**  \n",
    "- **Цель:** Приближённое вычисление $\\int_a^b f(x)  dx$.  \n",
    "- **Алгоритм:**  \n",
    "  1. Выбрать узлы $x_0 < x_1 < \\cdots < x_n$ на $[a, b]$.  \n",
    "  2. Построить интерполяционный многочлен $P_n(x)$ степени $n$ через $f(x_k)$.  \n",
    "  3. Интегрировать $P_n(x)$:  \n",
    "  $$\n",
    "  \\int_a^b f(x)  dx \\approx \\sum_{k=0}^n w_k f(x_k), \\quad w_k = \\int_a^b L_k(x)  dx,\n",
    "  $$  \n",
    "  где $L_k(x)$ — базис Лагранжа.  \n",
    "- **Ключевое:** Веса $w_k$ зависят только от узлов, не от $f(x)$.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Формулы Ньютона-Котеса**  \n",
    "**(Равноотстоящие узлы, включая концы отрезка: $x_k = a + kh$, $h = \\frac{b-a}{n}$)**  \n",
    "\n",
    "| Формула       | Узлы                           | Веса                                    | Формула вычисления                                  | Погрешность                     |\n",
    "|---------------|--------------------------------|-----------------------------------------|-----------------------------------------------------|----------------------------------|\n",
    "| **Трапеций**  | $a, b$                       | $w_0 = w_1 = \\frac{h}{2}$             | $\\frac{h}{2} \\left[ f(a) + f(b) \\right]$          | $-\\frac{h^3}{12} f''(\\xi)$     |\n",
    "| ($n=1$)     |                                |                                         |                                                     |                                  |\n",
    "| **Симпсона**  | $a, a+h, b$                  | $w_0 = w_2 = \\frac{h}{3}$, $w_1 = \\frac{4h}{3}$ | $\\frac{h}{3} \\left[ f(a) + 4f(a+h) + f(b) \\right]$ | $-\\frac{h^5}{90} f^{(4)}(\\xi)$ |\n",
    "| ($n=2$)     |                                |                                         |                                                     |                                  |\n",
    "| **Ньютона**   | $a, a+h, a+2h, b$            | $w_0 = w_3 = \\frac{3h}{8}$, $w_1 = w_2 = \\frac{9h}{8}$ | $\\frac{3h}{8} \\left[ f(a) + 3f(a+h) + 3f(a+2h) + f(b) \\right]$ | $-\\frac{3h^5}{80} f^{(4)}(\\xi)$ |\n",
    "| ($n=3$)     |                                |                                         |                                                     |                                  |\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Порядок точности**  \n",
    "- Максимальная степень многочлена, интегрируемого **точно**:  \n",
    "  - Трапеций: 1 (линейные функции).  \n",
    "  - Симпсона: 3 (кубические функции).  \n",
    "  - Ньютона ($n=3$): 3 (кубические функции).  \n",
    "- **Важно!** Формулы с нечётным $n$ имеют тот же порядок, что формулы с $n+1$ узлами.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Примеры для иллюстрации**  \n",
    "1. **Трапеций для $f(x) = x^2$ на $[0, 1]$**:  \n",
    "   - Точное значение: $\\frac{1}{3} \\approx 0.3333$.  \n",
    "   - Расчёт: $\\frac{1}{2} \\left[ 0 + 1 \\right] = 0.5$.  \n",
    "   - Погрешность: $0.1667$ (замена кривой прямой даёт завышение).  \n",
    "\n",
    "2. **Симпсона для $f(x) = x^3$ на $[0, 2]$**:  \n",
    "   - Точное значение: $4$.  \n",
    "   - Расчёт: $\\frac{1}{3} \\left[ 0 + 4 \\cdot 1 + 8 \\right] = 4$ (кубики интегрируются точно).  \n",
    "\n",
    "3. **Ньютона ($n=3$) для $f(x) = \\sin x$ на $[0, \\pi]$**:  \n",
    "   - Точное значение: $2$.  \n",
    "   - Расчёт: $\\frac{\\pi}{8} \\cdot 3\\sqrt{3} \\approx 2.0405$.  \n",
    "   - Погрешность: $0.0405$ (увеличение узлов повышает точность).\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Выводы**  \n",
    "- **Простота vs. Точность:** Трапеции — грубее, Симпсон — оптимален для гладких функций.  \n",
    "- **Ограничения:** Формулы Ньютона-Котеса с $n > 9$ неустойчивы (отрицательные веса).  \n",
    "- **Применение:** Для быстроосциллирующих функций уменьшайте шаг $h$ или используйте составные формулы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e017b1",
   "metadata": {},
   "source": [
    "<h1>14 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c695b",
   "metadata": {},
   "source": [
    "### Подробный разбор экзаменационного билета\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Формулы наивысшего порядка точности (Гаусса)\n",
    "**Суть:**  \n",
    "Формулы Гаусса достигают максимально возможного порядка точности **2n+1** для n+1 узлов (в отличие от формул Ньютона-Котеса, где порядок ≤ n+1). Узлы выбираются как корни многочленов, ортогональных на отрезке интегрирования.\n",
    "\n",
    "**Как это работает:**\n",
    "- Узлы не равноотстоящие, а расположены в корнях ортогональных многочленов (например, Лежандра для отрезка [-1, 1]).\n",
    "- Веса рассчитываются так, чтобы формула была точна для многочленов степени до 2n+1.\n",
    "- **Преимущество:** Для гладких функций точность выше, чем у Ньютона-Котеса при том же числе узлов.\n",
    "\n",
    "**Пример:**  \n",
    "Вычислим интеграл ∫₁⁻¹ x⁴ dx точным значением 2/5 = 0.4.  \n",
    "- **Формула Гаусса с 2 узлами** (корни многочлена Лежандра P₂(x): ±1/√3 ≈ ±0.577):  \n",
    "  Веса: w₁ = w₂ = 1.  \n",
    "  Приближение: (0.577)⁴ + (-0.577)⁴ ≈ 0.111 + 0.111 = 0.222 ❌ (погрешность 45%).  \n",
    "- **Формула Гаусса с 3 узлами** (корни P₃(x): 0, ±√(3/5) ≈ ±0.774):  \n",
    "  Веса: w₁ = 8/9 ≈ 0.889, w₂ = w₃ = 5/9 ≈ 0.556.  \n",
    "  Приближение:  \n",
    "  0.889·(0)⁴ + 0.556·(0.774)⁴ + 0.556·(-0.774)⁴ ≈ 0 + 0.556·0.359 + 0.556·0.359 ≈ 0.4 ✅ (точное значение).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Интегрирование с весовой функцией\n",
    "**Суть:**  \n",
    "Если подынтегральная функция имеет вид f(x) = g(x)·p(x), где p(x) — \"вес\" (например, p(x) = e⁻ˣ, √(1-x²)), то строят специализированные квадратурные формулы, точно учитывающие p(x).\n",
    "\n",
    "**Как это работает:**\n",
    "- p(x) выделяют в весовую функцию.\n",
    "- Узлы выбирают как корни многочленов, ортогональных с весом p(x) (например, Чебышева для p(x)=1/√(1-x²)).\n",
    "- Ошибка зависит только от аппроксимации g(x) многочленом.\n",
    "\n",
    "**Пример:**  \n",
    "Интеграл ∫₁⁻¹ √(1-x²) dx (площадь полукруга, точное значение π/2 ≈ 1.571).  \n",
    "- **Обычная формула Гаусса (без веса):**  \n",
    "  При 5 узлах погрешность ~10⁻² (требует много узлов из-за особенностей на концах).  \n",
    "- **Формула Гаусса-Чебышева 2-го рода** (вес p(x)=√(1-x²), узлы — корни Uₙ(x)):  \n",
    "  Для n=2: узлы ±√(2)/2 ≈ ±0.707, веса w₁=w₂=π/4 ≈ 0.785.  \n",
    "  Приближение: g(x)=1 ⇒ ∑wₖ·g(xₖ) = 0.785·1 + 0.785·1 = 1.57 ✅ (погрешность < 0.01%).\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Интегрирование с контролем точности (алгоритм Рунге)\n",
    "**Суть:**  \n",
    "Автоматическое адаптивное вычисление интеграла с оценкой погрешности. Отрезок дробится, пока разность между двумя приближениями не станет меньше заданной точности ε.\n",
    "\n",
    "**Алгоритм для формулы Симпсона:**\n",
    "1. **Инициализация:**  \n",
    "   - Разбить [a, b] на 1 интервал (шаг h = b-a).  \n",
    "   - Вычислить S₁ = f(a) + f(b).  \n",
    "2. **Итерация:**  \n",
    "   - Добавить узлы в серединах новых подынтервалов.  \n",
    "   - Вычислить S₂ (значения в новых узлах).  \n",
    "   - Обновить S₃ = S₃ + S₂ (старые внутренние узлы).  \n",
    "   - Новое приближение: I = (h/3)·(S₁ + 4S₂ + 2S₃).  \n",
    "3. **Оценка погрешности:**  \n",
    "   - ΔI = |Iₜₕᵢₛ − Iₚᵣₑᵥ| ≈ |R| (по формуле Рунге).  \n",
    "   - Если ΔI < ε → остановка, иначе h = h/2, повтор шага 2.\n",
    "\n",
    "**Пример:**  \n",
    "∫₀¹ e⁻ˣ² dx (точное значение ≈ 0.7468).  \n",
    "- **Шаг 1:** h=1, S₁ = f(0)+f(1)=1+0.3679=1.3679 → I₁ = (1/3)·1.3679 ≈ 0.456 (погрешность 39%).  \n",
    "- **Шаг 2:** h=0.5, добавить узлы x=0.5, x=1.5 (не входит в [0,1]).  \n",
    "  S₂ = f(0.5)=0.7788 → I₂ = (0.5/3)·[1.3679 + 4·0.7788] ≈ 0.708 (ΔI=|0.708-0.456|=0.252 > ε).  \n",
    "- **Шаг 3:** h=0.25, добавить узлы x=0.25, x=0.75.  \n",
    "  S₂ = f(0.25)+f(0.75)≈0.9394+0.5698=1.5092 → I₃=0.746 (ΔI=|0.746-0.708|=0.038 < ε для ε=0.05).  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Вычисление несобственных интегралов\n",
    "**Подходы:**  \n",
    "1. **Формулы Гаусса для бесконечных интервалов:**  \n",
    "   - Лагерра: для [0, ∞) с весом e⁻ˣ.  \n",
    "   - Эрмита: для (-∞, ∞) с весом e⁻ˣ².  \n",
    "2. **Замена переменных:** Например, x = t/(1-t) для [a, ∞) → [0, 1].\n",
    "\n",
    "**Пример:**  \n",
    "∫₀^∞ e⁻ˣ·sin(x) dx (точное значение = 0.5).  \n",
    "- **Формула Гаусса-Лагерра** (n=3):  \n",
    "  Узлы: 0.4158, 1.2943, 3.6353; веса: 0.711, 0.278, 0.011.  \n",
    "  Приближение: ∑wₖ·sin(xₖ) ≈ 0.711·0.401 + 0.278·0.963 + 0.011·(-0.475) ≈ 0.5 ✅.\n",
    "\n",
    "---\n",
    "\n",
    "### Итог\n",
    "- **Формулы Гаусса** дают высокую точность для гладких функций на конечных интервалах.  \n",
    "- **Весовые функции** устраняют особенности (например, бесконечные производные на концах).  \n",
    "- **Алгоритм Рунге** автоматически адаптирует шаг под требуемую точность.  \n",
    "- **Несобственные интегралы** вычисляются через специализированные квадратуры или замены переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82696b",
   "metadata": {},
   "source": [
    "<h1>14 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855e2a1",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Формулы наивысшего порядка точности (Гаусса)\n",
    "- **Суть:** Максимальный порядок точности **2n+1** для n+1 узлов достигается выбором узлов в корнях ортогональных многочленов (например, Лежандра для [-1, 1]).  \n",
    "- **Преимущество:** Точнее формул Ньютона-Котеса при том же числе узлов.  \n",
    "- **Пример:**  \n",
    "  ∫₁⁻¹ x⁴ dx ≈ 0.4. Формула Гаусса с 3 узлами (корни P₃(x): 0, ±√(3/5)) даёт точное значение.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Интегрирование с весовой функцией\n",
    "- **Суть:** Для f(x) = g(x)·p(x) (особенно при особенностях) строят формулы с узлами — корнями многочленов, ортогональных с весом p(x).  \n",
    "- **Метод:** p(x) включается в веса, ошибка зависит только от g(x).  \n",
    "- **Пример:**  \n",
    "  ∫₁⁻¹ √(1-x²) dx ≈ 1.571. Формула Гаусса-Чебышёва 2-го рода (вес p(x)=√(1-x²)) при 2 узлах даёт 1.57.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Алгоритм интегрирования с контролем точности (Рунге)\n",
    "- **Шаги:**  \n",
    "  1. Инициализация: S₁ = f(a) + f(b), h = b-a.  \n",
    "  2. Цикл:  \n",
    "     - Добавить узлы в серединах новых подынтервалов → вычислить S₂.  \n",
    "     - Обновить S₃ = S₃ + S₂.  \n",
    "     - I = (h/3)·(S₁ + 4S₂ + 2S₃).  \n",
    "     - Если |I - I_пред| < ε → выход, иначе h = h/2.  \n",
    "- **Пример:**  \n",
    "  ∫₀¹ e⁻ˣ² dx ≈ 0.7468. При ε=0.05: после 3 итераций I=0.746.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Вычисление несобственных интегралов\n",
    "- **Методы:**  \n",
    "  - Гаусса-Лагерра: для [0, ∞) с весом e⁻ˣ.  \n",
    "  - Гаусса-Эрмита: для (-∞, ∞) с весом e⁻ˣ².  \n",
    "  - Замена переменных (например, x = t/(1-t) для [a, ∞)).  \n",
    "- **Пример:**  \n",
    "  ∫₀^∞ e⁻ˣ·sin(x) dx = 0.5. Формула Гаусса-Лагерра (n=3) даёт точное значение.\n",
    "\n",
    "---\n",
    "\n",
    "### Ключевые выводы\n",
    "- **Гаусс:** Ортогональные многочлены → высокая точность.  \n",
    "- **Весовая функция:** Учёт особенностей через p(x).  \n",
    "- **Рунге:** Адаптивное разбиение отрезка по оценке погрешности.  \n",
    "- **Несобственные интегралы:** Специализированные квадратуры или замена переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7db824",
   "metadata": {},
   "source": [
    "<h1>15 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757c08d",
   "metadata": {},
   "source": [
    "### Подробный разбор экзаменационного билета  \n",
    "**Тема:** Численные методы решения задачи Коши для обыкновенных дифференциальных уравнений (ОДУ), анализ ошибок и устойчивости, сравнение явных и неявных методов.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Задача Коши**  \n",
    "**Определение:**  \n",
    "Задача Коши требует найти решение ОДУ $ y' = F(x, y) $ с начальным условием $ y(x_0) = y_0 $. Численное решение строится в точках $ x_0, x_1, \\ldots, x_m $ с шагом $ h $.  \n",
    "\n",
    "**Пример:**  \n",
    "Уравнение радиоактивного распада:  \n",
    "$$ \\frac{dA}{dt} = -kA, \\quad A(0) = A_0. $$  \n",
    "Аналитическое решение: $ A(t) = A_0 e^{-kt} $.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Метод Эйлера (явный)**  \n",
    "**Формула:**  \n",
    "$$ y_{n+1} = y_n + h \\cdot F(x_n, y_n) $$  \n",
    "**Суть:**  \n",
    "Аппроксимация решения прямой линией с наклоном касательной в начальной точке шага.  \n",
    "**Недостаток:** Низкая точность (погрешность $ O(h^2) $ на шаге).  \n",
    "\n",
    "**Пример:**  \n",
    "Для уравнения $ y' = -y $, $ y(0) = 1 $, $ h = 0.1 $:  \n",
    "- Точное решение: $ y(1) = e^{-1} \\approx 0.3679 $.  \n",
    "- Численное решение:  \n",
    "  $$ y_1 = 1 + 0.1 \\cdot (-1) = 0.9, \\quad y_2 = 0.9 + 0.1 \\cdot (-0.9) = 0.81, \\ldots, \\quad y_{10} \\approx 0.3487. $$  \n",
    "Ошибка накопления: $ |0.3487 - 0.3679| \\approx 0.0192 $.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Локальная и глобальная ошибки**  \n",
    "- **Локальная ошибка:** Отклонение на одном шаге, если предыдущая точка точна. Для метода Эйлера: $ O(h^2) $.  \n",
    "- **Глобальная ошибка:** Суммарное отклонение после $ n $ шагов. Для метода Эйлера: $ O(h) $.  \n",
    "\n",
    "**Анализ:**  \n",
    "Глобальная ошибка зависит от поведения решения:  \n",
    "- Если $ \\lambda = \\frac{\\partial F}{\\partial y} < 0 $ (решение убывает), ошибка может затухать.  \n",
    "- Если $ \\lambda > 0 $ (решение растет), ошибка растет экспоненциально.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Устойчивость**  \n",
    "**Определение:**  \n",
    "Решение **устойчиво**, если малые ошибки не накапливаются лавинообразно.  \n",
    "\n",
    "**Критерий для явного метода Эйлера:**  \n",
    "- При $ \\lambda < 0 $: устойчиво, если $ h < \\frac{2}{|\\lambda|} $.  \n",
    "- При $ \\lambda > 0 $: неустойчиво всегда.  \n",
    "\n",
    "**Пример:**  \n",
    "Для $ y' = -1000y $ (быстрое убывание):  \n",
    "- Максимальный шаг для устойчивости: $ h < \\frac{2}{1000} = 0.002 $.  \n",
    "- При $ h = 0.003 $: решение \"раскачивается\", значения колеблются и растут.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Неявный метод Эйлера**  \n",
    "**Формула:**  \n",
    "$$ y_{n+1} = y_n + h \\cdot F(x_{n+1}, y_{n+1}) $$  \n",
    "**Суть:**  \n",
    "Касательная берется в **конечной** точке шага. Требует решения уравнения (итерационно).  \n",
    "\n",
    "**Преимущества:**  \n",
    "- **A-устойчивость** при $ \\lambda < 0 $: устойчив для любого $ h $.  \n",
    "- Лучшая точность для жестких систем.  \n",
    "\n",
    "**Пример:**  \n",
    "Для $ y' = -1000y $, $ y(0) = 1 $:  \n",
    "- При $ h = 0.1 $:  \n",
    "  $$ y_{n+1} = \\frac{y_n}{1 + 1000 \\cdot 0.1} = \\frac{y_n}{101} \\implies y_1 \\approx 0.0099, \\quad y_2 \\approx 9.8 \\cdot 10^{-5}. $$  \n",
    "Решение устойчиво даже при большом шаге.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Жесткие системы ОДУ**  \n",
    "**Определение:**  \n",
    "Системы, где компоненты решения меняются с резко разными скоростями (например, $ |\\lambda_{\\text{max}}| \\gg |\\lambda_{\\text{min}}| $).  \n",
    "\n",
    "**Проблема явных методов:**  \n",
    "Шаг ограничен самой быстрой компонентой, что ведет к огромному числу шагов.  \n",
    "\n",
    "**Пример из химии:**  \n",
    "Система кинетических уравнений радиолиза метанола:  \n",
    "- Константы скоростей: от $ 10^3 $ до $ 10^{11} $ с⁻¹.  \n",
    "- Для метода Рунге-Кутты (явный): шаг $ h < 10^{-9} $ с.  \n",
    "- Интегрирование до $ t = 100 $ с потребовало бы $ 10^{11} $ шагов и ≈20 лет расчета.  \n",
    "- **Метод Гира** (неявный, A-устойчивый): решил задачу за 806 шагов за 15 секунд.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Сравнение явных и неявных методов**  \n",
    "| **Критерий**       | **Явный метод**       | **Неявный метод**     |  \n",
    "|---------------------|------------------------|------------------------|  \n",
    "| **Формула**         | $ y_{n+1} = y_n + h F(x_n, y_n) $ | $ y_{n+1} = y_n + h F(x_{n+1}, y_{n+1}) $ |  \n",
    "| **Устойчивость**    | Требует малого $ h $ | A-устойчив при $ \\lambda < 0 $ |  \n",
    "| **Сложность**       | Прост в реализации    | Требует решения уравнения |  \n",
    "| **Применение**      | Нежесткие системы     | Жесткие системы (химическая кинетика) |  \n",
    "\n",
    "---\n",
    "\n",
    "### Резюме  \n",
    "- **Локальная ошибка** — погрешность на одном шаге, **глобальная** — накопленная.  \n",
    "- **Устойчивость** критична для жестких систем: неявные методы (например, Эйлера, Гира) позволяют брать большие шаги.  \n",
    "- **Жесткие системы** требуют A-устойчивых методов: в противном случае шаг ограничен быстро меняющимися компонентами, что делает расчеты нереализуемыми.  \n",
    "\n",
    "Для успешной сдачи экзамена важно понимать, как выбор метода влияет на устойчивость и точность решения, особенно при моделировании реальных физико-химических процессов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2702d1",
   "metadata": {},
   "source": [
    "<h1>15 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bdf10",
   "metadata": {},
   "source": [
    "### Ответ на экзаменационный билет:  \n",
    "**1. Задача Коши:**  \n",
    "Решение ОДУ $ y' = F(x, y) $ с начальным условием $ y(x_0) = y_0 $. Численный ответ — таблица значений $ y_i $ в точках $ x_i $.  \n",
    "\n",
    "**2. Метод Эйлера (явный):**  \n",
    "$$ y_{n+1} = y_n + h \\cdot F(x_n, y_n) $$  \n",
    "- **Порядок точности:** 1 (локальная ошибка $ O(h^2) $).  \n",
    "- **Недостатки:** Низкая точность, ограниченная устойчивость.  \n",
    "\n",
    "**3. Ошибки:**  \n",
    "- **Локальная:** Погрешность на одном шаге ($ O(h^2) $ для Эйлера).  \n",
    "- **Глобальная:** Накопленное отклонение после $ n $ шагов ($ O(h) $ для Эйлера).  \n",
    "\n",
    "**4. Устойчивость:**  \n",
    "- **Явный метод Эйлера:**  \n",
    "  - Устойчив при $ \\lambda = \\frac{\\partial F}{\\partial y} < 0 $ и $ h < \\frac{2}{|\\lambda|} $.  \n",
    "  - Неустойчив при $ \\lambda > 0 $ или больших $ h $.  \n",
    "- **Неявный метод Эйлера:**  \n",
    "  $$ y_{n+1} = y_n + h \\cdot F(x_{n+1}, y_{n+1}) $$  \n",
    "  - **A-устойчивость** при $ \\lambda < 0 $ (устойчив для любого $ h $!).  \n",
    "\n",
    "**5. Жесткие системы:**  \n",
    "- Компоненты решения меняются с резко разными скоростями ($ |\\lambda_{\\text{max}}| \\gg |\\lambda_{\\text{min}}| $).  \n",
    "- **Проблема явных методов:** Шаг $ h $ ограничен быстрой компонентой → нереализуемо много шагов.  \n",
    "- **Решение:** Неявные методы (Гира, A-устойчивые).  \n",
    "\n",
    "**6. Сравнение методов:**  \n",
    "| **Критерий**   | **Явный метод**       | **Неявный метод**     |  \n",
    "|----------------|------------------------|------------------------|  \n",
    "| **Устойчивость** | Ограничена $ h $      | A-устойчивость         |  \n",
    "| **Точность**   | Низкая (1-й порядок)   | Выше (1-й порядок)      |  \n",
    "| **Применение** | Нежесткие системы      | Жесткие системы        |  \n",
    "\n",
    "---\n",
    "\n",
    "### Выводы:  \n",
    "1. Для **нежестких систем** подходят явные методы (Рунге-Кутты 4-го порядка).  \n",
    "2. Для **жестких систем** (химкинетика) обязательны **неявные A-устойчивые методы** (Эйлера неявный, Гира).  \n",
    "3. **Устойчивость > Точность:** Если решение \"раскачивается\", уменьшите $ h $ или выберите неявный метод."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1624aef",
   "metadata": {},
   "source": [
    "<h1>16 билет. <b style=\"color:red;\">К прочтению</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab5c7c",
   "metadata": {},
   "source": [
    "### Подробный разбор экзаменационного билета:  \n",
    "**Тема:** Численные методы решения обыкновенных дифференциальных уравнений (ОДУ).  \n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Порядок решения ОДУ**  \n",
    "**Суть:** Решение задачи Коши $ y' = F(x, y) $, $ y(x_0) = y_0 $ выполняется последовательно, шаг за шагом, от начальной точки $ x_0 $ до конечной $ x_m $.  \n",
    "**Этапы:**  \n",
    "1. **Задание шага $ h $:**  \n",
    "   - Фиксированный шаг: $ h = \\text{const} $ (просто, но может быть неэффективно).  \n",
    "   - Переменный шаг: $ h $ адаптируется под точность (сложнее, но экономичнее).  \n",
    "2. **Выбор метода:** Определяет, как вычислять $ y_{n+1} $ по известным $ y_n $.  \n",
    "3. **Итерации:** На каждом шаге применяется выбранная схема.  \n",
    "4. **Контроль ошибки:** Оценка погрешности и корректировка $ h $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Модифицированный метод Эйлера**  \n",
    "**Суть:** Улучшенная версия явного метода Эйлера с повышением точности до 2-го порядка.  \n",
    "**Алгоритм (два этапа):**  \n",
    "1. **Прогноз (явный шаг):**  \n",
    "   $$\n",
    "   \\hat{y}_{n+1} = y_n + h \\cdot F(x_n, y_n).\n",
    "   $$  \n",
    "2. **Коррекция (усреднение производных):**  \n",
    "   $$\n",
    "   y_{n+1} = y_n + h \\cdot \\frac{F(x_n, y_n) + F(x_{n+1}, \\hat{y}_{n+1})}{2}.\n",
    "   $$  \n",
    "**Почему лучше?**  \n",
    "- Локальная ошибка: $ O(h^3) $ (против $ O(h^2) $ у стандартного Эйлера).  \n",
    "- Геометрическая интерпретация: использует средний наклон касательных в точках $ x_n $ и $ x_{n+1} $.  \n",
    "\n",
    "**Пример:**  \n",
    "Решим $ y' = -y $, $ y(0) = 1 $ на $[0, 1]$ с $ h = 0.5 $:  \n",
    "- **Шаг 1 ($ x_0 = 0 $):**  \n",
    "  Прогноз: $ \\hat{y}_1 = 1 + 0.5 \\cdot (-1) = 0.5 $.  \n",
    "  Коррекция: $ y_1 = 1 + 0.5 \\cdot \\frac{-1 + (-0.5)}{2} = 1 + 0.5 \\cdot (-0.75) = 0.625 $.  \n",
    "- **Шаг 2 ($ x_1 = 0.5 $):**  \n",
    "  Прогноз: $ \\hat{y}_2 = 0.625 + 0.5 \\cdot (-0.625) = 0.3125 $.  \n",
    "  Коррекция: $ y_2 = 0.625 + 0.5 \\cdot \\frac{-0.625 + (-0.3125)}{2} = 0.625 - 0.234375 = 0.390625 $.  \n",
    "Точное решение: $ y = e^{-1} \\approx 0.367 $. Погрешность: $ |0.391 - 0.367| \\approx 0.024 $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Метод Рунге-Кутты 4-го порядка**  \n",
    "**Суть:** Вычисляет производные в 4 вспомогательных точках для повышения точности до $ O(h^5) $.  \n",
    "**Формулы:**  \n",
    "$$\n",
    "\\begin{align*}\n",
    "k_1 &= F(x_n, y_n), \\\\\n",
    "k_2 &= F\\left(x_n + \\frac{h}{2}, y_n + \\frac{h}{2} k_1\\right), \\\\\n",
    "k_3 &= F\\left(x_n + \\frac{h}{2}, y_n + \\frac{h}{2} k_2\\right), \\\\\n",
    "k_4 &= F(x_n + h, y_n + h k_3), \\\\\n",
    "y_{n+1} &= y_n + \\frac{h}{6} (k_1 + 2k_2 + 2k_3 + k_4).\n",
    "\\end{align*}\n",
    "$$  \n",
    "**Преимущества:**  \n",
    "- Высокая точность (погрешность шага $ \\sim h^5 $).  \n",
    "- Универсальность (не требует вычисления старших производных).  \n",
    "\n",
    "**Пример:**  \n",
    "Для $ y' = -y $, $ y(0) = 1 $, $ h = 1 $:  \n",
    "- $ k_1 = -1 $,  \n",
    "- $ k_2 = F(0.5, 1 + 0.5 \\cdot (-1)) = F(0.5, 0.5) = -0.5 $,  \n",
    "- $ k_3 = F(0.5, 1 + 0.5 \\cdot (-0.5)) = F(0.5, 0.75) = -0.75 $,  \n",
    "- $ k_4 = F(1, 1 + 1 \\cdot (-0.75)) = F(1, 0.25) = -0.25 $,  \n",
    "- $ y_1 = 1 + \\frac{1}{6}(-1 + 2 \\cdot (-0.5) + 2 \\cdot (-0.75) + (-0.25)) = 1 - 0.75 = 0.25 $.  \n",
    "Точное решение: $ e^{-1} \\approx 0.367 $. Погрешность: $ |0.25 - 0.367| = 0.117 $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Многошаговые методы (Методы прогноза-коррекции)**  \n",
    "**Суть:** Используют значения $ y $ и $ y' $ в нескольких предыдущих точках.  \n",
    "**Примеры:**  \n",
    "- **Метод Адамса-Башфорта (4-й порядок):**  \n",
    "  **Прогноз (явный):**  \n",
    "  $$\n",
    "  y_{n+1} = y_n + \\frac{h}{24} (55y_n' - 59y_{n-1}' + 37y_{n-2}' - 9y_{n-3}').\n",
    "  $$  \n",
    "  **Коррекция (неявный):**  \n",
    "  $$\n",
    "  y_{n+1} = y_n + \\frac{h}{24} (9y_{n+1}' + 19y_n' - 5y_{n-1}' + y_{n-2}').\n",
    "  $$  \n",
    "- **Особенности:**  \n",
    "  - Требуют стартовых точек (вычисленных, например, методом Рунге-Кутты).  \n",
    "  - Экономичны (меньше вычислений $ F(x, y) $ на шаг).  \n",
    "  - Локальная ошибка коррекции в 20–30 раз меньше, чем у прогноза.  \n",
    "\n",
    "**Пример (упрощенный):**  \n",
    "Для системы:  \n",
    "$$\n",
    "\\begin{cases}\n",
    "y_1' = -0.7y_1 + 0.25y_2 \\\\\n",
    "y_2' = 0.25y_1 - 1.9y_2\n",
    "\\end{cases}\n",
    "$$  \n",
    "с начальными условиями $ y_1(0) = 1.2 $, $ y_2(0) = 0.8 $.  \n",
    "- Первые 4 точки вычисляем методом Рунге-Кутты.  \n",
    "- Далее используем метод Адамса-Башфорта.  \n",
    "Решение покажет два масштаба времени: быстрый спад $ y_2 $ и медленное изменение $ y_1 $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Контроль точности и выбор шага**  \n",
    "**Стратегии:**  \n",
    "1. **Оценка локальной ошибки:**  \n",
    "   - Сравнение прогноза и коррекции (в методах Адамса/Милна).  \n",
    "   - Разница решений для разных $ h $ (метод Рунге).  \n",
    "2. **Адаптивный шаг:**  \n",
    "   - Если ошибка $ \\delta > \\delta_{\\text{доп}} $, уменьшают $ h $ (например, в 2 раза).  \n",
    "   - Если $ \\delta < \\delta_{\\text{доп}}/10 $, увеличивают $ h $.  \n",
    "**Пример:** В Python-библиотеке `scipy.integrate.solve_ivp` используется автоматический выбор шага на основе оценки погрешности.  \n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Алгоритмы с фиксированным шагом**  \n",
    "**Плюсы:** Простота реализации.  \n",
    "**Минусы:** Риск неустойчивости или избыточных вычислений.  \n",
    "**Пример:** Метод Эйлера для $ y' = -1000y $, $ y(0) = 1 $:  \n",
    "- Требует $ h < 0.002 $ для устойчивости, хотя решение $ y = e^{-1000x} $ быстро стремится к 0.  \n",
    "- При $ h = 0.001 $ нужно 1000 шагов для $ x \\in [0, 1] $, при этом на большей части интервала $ y \\approx 0 $.  \n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Решение жестких систем**  \n",
    "**Проблема:** В системах вида $ \\mathbf{y}' = A\\mathbf{y} $ (например, химическая кинетика) собственные значения $ \\lambda_i $ матрицы $ A $ сильно различаются (например, $ \\lambda_1 = -1 $, $ \\lambda_2 = -1000 $).  \n",
    "**Чем опасно:**  \n",
    "- Явные методы требуют $ h < 2 / |\\lambda_{\\max}| $ (здесь $ h < 0.002 $), но интерес представляет интервал, где доминирует медленная компонента ($ e^{-x} $).  \n",
    "**Решение:**  \n",
    "- **Неявные методы** (например, неявный Эйлер, метод Гира).  \n",
    "- **Метод Гира (Gear):**  \n",
    "  - Неявный, переменный порядок (1–6), автоматический выбор шага.  \n",
    "  - Жестко устойчив.  \n",
    "**Пример из лекции:** Модель радиолиза метанола (37 реакций).  \n",
    "- Метод Рунге-Кутты: шаг $ h = 10^{-9} $ с, время расчета до $ t = 4 \\cdot 10^{-5} $ с — 5 минут.  \n",
    "- Метод Гира: до $ t = 100 $ с — 806 шагов за 15 секунд.  \n",
    "\n",
    "---\n",
    "\n",
    "### Итоговая таблица сравнения методов  \n",
    "| **Метод**               | **Порядок** | **Тип**       | **Устойчивость**       | **Применение**         |  \n",
    "|--------------------------|-------------|---------------|------------------------|------------------------|  \n",
    "| Явный Эйлер             | 1           | Явный         | Условная ($ h < 2/\\|\\lambda\\| $) | Простые ОДУ          |  \n",
    "| Модифицированный Эйлер  | 2           | Явный         | Условная               | Умеренно сложные ОДУ |  \n",
    "| Рунге-Кутты 4           | 4           | Явный         | Условная               | Универсальный         |  \n",
    "| Адамс-Башфорт           | 4           | Прогноз-коррекция | Условная          | Экономичные расчеты   |  \n",
    "| Неявный Эйлер           | 1           | Неявный       | A-устойчивость         | Жесткие системы       |  \n",
    "| Метод Гира              | 1–6         | Неявный       | Жесткая устойчивость   | Сверхжесткие системы  |  \n",
    "\n",
    "Для успешной сдачи экзамена важно понимать:  \n",
    "- Разницу между явными/неявными схемами,  \n",
    "- Связь порядка метода с точностью,  \n",
    "- Причины жесткости и способы ее преодоления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f14f68",
   "metadata": {},
   "source": [
    "<h1>16 билет. <b style=\"color:red;\">Записать в тетрадь</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf26b28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
